{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-18T03:32:36.931299400Z",
     "start_time": "2025-12-18T03:32:34.508413200Z"
    }
   },
   "source": [
    "import html\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# ================= CONFIG =================\n",
    "BASE_LIST_URL = \"https://meeyland.com/mua-ban-nha-dat-ho-chi-minh-b43?page={}\"\n",
    "START_PAGE = 1\n",
    "END_PAGE = 1       # Ch·ªânh s·ªë trang c·∫ßn c√†o\n",
    "CHECKPOINT_PAGE = 50  # L∆∞u checkpoint m·ªói 50 trang\n",
    "MAX_WORKERS = 4\n",
    "OUTPUT_FINAL = \"meeyland_hcm_final.csv\"\n",
    "\n",
    "# ================= UTILS =================\n",
    "def extract_id(link):\n",
    "    m = re.search(r\"/(\\d{6,})$\", link)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def price_to_billion(text):\n",
    "    if not text: return None\n",
    "    t = text.lower().replace(\",\", \".\")\n",
    "    m = re.search(r\"([\\d\\.]+)\", t)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def clean_area(text):\n",
    "    if not text: return None\n",
    "    m = re.search(r\"([\\d\\.]+)\\s*m\", text.lower())\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def extract_district(address):\n",
    "    if not address: return \"N/A\"\n",
    "    addr = address.lower()\n",
    "    if \"th·ªß ƒë·ª©c\" in addr: return \"TP Th·ªß ƒê·ª©c\"\n",
    "    m = re.search(r\"(qu·∫≠n\\s*\\d+|q\\.\\d+|qu·∫≠n\\s*[a-z√†-·ªπ\\s]+|huy·ªán\\s*[a-z√†-·ªπ\\s]+)\", addr)\n",
    "    return m.group(1).title() if m else \"N/A\"\n",
    "\n",
    "# ================= DRIVER =================\n",
    "def init_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--window-size=1366,768\")\n",
    "    options.add_argument(\"--headless\")\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ================= CRAWL DETAIL =================\n",
    "def crawl_detail_task(url, page_num):\n",
    "    driver = init_driver()\n",
    "    # Kh·ªüi t·∫°o ƒë√∫ng c√°c tr∆∞·ªùng theo ·∫£nh b·∫°n g·ª≠i\n",
    "    data = {\n",
    "        \"id\": extract_id(url),\n",
    "        \"Page\": page_num,\n",
    "        \"Title\": \"N/A\",\n",
    "        \"Price_Raw\": \"N/A\",\n",
    "        \"Price_Billion\": None,\n",
    "        \"Area_m2\": None,\n",
    "        \"District\": \"N/A\",\n",
    "        \"Address\": \"N/A\",\n",
    "        \"Bedrooms\": None,\n",
    "        \"Toilets\": None,\n",
    "        \"Post_Time\": \"N/A\",\n",
    "        \"Link\": url,\n",
    "        \"Description\": \"N/A\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "\n",
    "        # Click \"Xem th√™m\" cho c·∫£ 2 ph·∫ßn\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH, \"//span[contains(text(),'Xem th√™m')]\")))\n",
    "            btns = driver.find_elements(By.XPATH, \"//span[contains(text(),'Xem th√™m')]\")\n",
    "            for b in btns: driver.execute_script(\"arguments[0].click();\", b)\n",
    "            time.sleep(0.5)\n",
    "        except: pass\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        # ƒê·ªï d·ªØ li·ªáu v√†o c√°c tr∆∞·ªùng c·ªë ƒë·ªãnh\n",
    "        data[\"Title\"] = soup.find(\"h1\").get_text(strip=True) if soup.find(\"h1\") else \"N/A\"\n",
    "\n",
    "        price_tag = soup.select_one(\"h2.text-error-600\")\n",
    "        if price_tag:\n",
    "            data[\"Price_Raw\"] = price_tag.get_text(strip=True)\n",
    "            data[\"Price_Billion\"] = price_to_billion(data[\"Price_Raw\"])\n",
    "\n",
    "        addr_tag = soup.select_one(\"div.text-fs-14.font-medium.text-primary-600\")\n",
    "        if addr_tag:\n",
    "            data[\"Address\"] = addr_tag.get_text(strip=True)\n",
    "            data[\"District\"] = extract_district(data[\"Address\"])\n",
    "\n",
    "        desc_div = soup.select_one(\"div.article-description div.break-words\")\n",
    "        data[\"Description\"] = desc_div.get_text(\" \", strip=True) if desc_div else \"N/A\"\n",
    "\n",
    "        # C√†o PN, WC, Di·ªán t√≠ch t·ª´ c√°c icon/span\n",
    "        spans = soup.select(\"span.text-fs-14\")\n",
    "        for sp in spans:\n",
    "            t = sp.get_text().lower()\n",
    "            if \"m2\" in t: data[\"Area_m2\"] = clean_area(t)\n",
    "            if \"pn\" in t:\n",
    "                m = re.search(r\"\\d+\", t)\n",
    "                if m: data[\"Bedrooms\"] = m.group()\n",
    "            if \"wc\" in t:\n",
    "                m = re.search(r\"\\d+\", t)\n",
    "                if m: data[\"Toilets\"] = m.group()\n",
    "\n",
    "        # C√†o ƒë·ªông m·ª•c \"Th√¥ng tin chi ti·∫øt\" (M·∫∑t ti·ªÅn, Chi·ªÅu s√¢u...)\n",
    "        prop_box = soup.find(\"div\", id=\"property\")\n",
    "        if prop_box:\n",
    "            items = prop_box.find_all(\"div\", class_=\"flex items-start\")\n",
    "            for item in items:\n",
    "                ss = item.find_all(\"span\")\n",
    "                if len(ss) >= 2:\n",
    "                    data[ss[0].get_text(strip=True)] = ss[1].get_text(strip=True)\n",
    "\n",
    "        post_tag = soup.find(\"p\", string=re.compile(\"Ng√†y ƒëƒÉng\"))\n",
    "        if post_tag: data[\"Post_Time\"] = post_tag.get_text().replace(\"Ng√†y ƒëƒÉng:\", \"\").strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   [ERR] {url[-10:]}: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return data\n",
    "\n",
    "# ================= MAIN =================\n",
    "def main():\n",
    "    all_data = []\n",
    "    batch_links = []\n",
    "\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U C√ÄO: {START_PAGE} -> {END_PAGE} (Checkpoint m·ªói {CHECKPOINT_PAGE} trang)\")\n",
    "    list_driver = init_driver()\n",
    "\n",
    "    try:\n",
    "        for p in range(START_PAGE, END_PAGE + 1):\n",
    "            print(f\"--- Qu√©t List Trang {p} ---\")\n",
    "            list_driver.get(BASE_LIST_URL.format(p))\n",
    "            time.sleep(1.5)\n",
    "            soup = BeautifulSoup(list_driver.page_source, \"html.parser\")\n",
    "\n",
    "            p_links = []\n",
    "            for a in soup.select(\"a[href]\"):\n",
    "                href = a[\"href\"]\n",
    "                if \"ho-chi-minh\" in href and re.search(r\"/\\d{6,}$\", href):\n",
    "                    full = \"https://meeyland.com\" + href\n",
    "                    if full not in [x[0] for x in batch_links]:\n",
    "                        p_links.append(full)\n",
    "                        batch_links.append((full, p)) # L∆∞u k√®m s·ªë trang\n",
    "\n",
    "            print(f\"   T√¨m th·∫•y {len(p_links)} tin.\")\n",
    "\n",
    "            if p % CHECKPOINT_PAGE == 0 or p == END_PAGE:\n",
    "                print(f\"\\n‚ö° ƒêang c√†o chi ti·∫øt Batch {len(batch_links)} link...\")\n",
    "                with ThreadPoolExecutor(max_workers=MAX_WORKERS) as exe:\n",
    "                    futures = [exe.submit(crawl_detail_task, link, p_num) for link, p_num in batch_links]\n",
    "                    for i, f in enumerate(futures):\n",
    "                        res = f.result()\n",
    "                        all_data.append(res)\n",
    "                        print(f\"   [{i+1}/{len(batch_links)}] Xong: {res['id']}\")\n",
    "\n",
    "                # L∆∞u checkpoint\n",
    "                pd.DataFrame(all_data).to_csv(f\"checkpoint_p{p}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "                batch_links = [] # Reset link cho ƒë·ª£t sau\n",
    "                print(f\"üíæ ƒê√£ l∆∞u checkpoint_p{p}.csv\\n\")\n",
    "\n",
    "    finally:\n",
    "        list_driver.quit()\n",
    "\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        # ƒê·∫£m b·∫£o c√°c c·ªôt c·ªë ƒë·ªãnh xu·∫•t hi·ªán ƒë·∫ßu ti√™n theo ƒë√∫ng th·ª© t·ª± ·∫£nh b·∫°n g·ª≠i\n",
    "        cols_fixed = [\"id\", \"Page\", \"Title\", \"Price_Raw\", \"Price_Billion\", \"Area_m2\", \"District\", \"Address\", \"Bedrooms\", \"Toilets\", \"Post_Time\", \"Link\", \"Description\"]\n",
    "        cols_dynamic = [c for c in df.columns if c not in cols_fixed]\n",
    "        df = df[cols_fixed + cols_dynamic]\n",
    "\n",
    "        df.to_csv(OUTPUT_FINAL, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"\\n‚úÖ HO√ÄN T·∫§T! T·ªïng {len(all_data)} tin. File: {OUTPUT_FINAL}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n",
      "usage: ipykernel_launcher.py [-h] [-v] [-s STYLE] [-b] [-j] identifier\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
