{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ki·ªÉm tra t·ªïng th·ªÉ tr∆∞·ªùng v√† s·ªë l∆∞·ª£ng data",
   "id": "ac30fe2942a2ab71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:13.164814400Z",
     "start_time": "2026-01-03T11:17:12.905164100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def inspect_csv(df):\n",
    "    print(\"===== CSV OVERVIEW =====\")\n",
    "    print(f\"Rows    : {df.shape[0]}\")\n",
    "    print(f\"Columns : {df.shape[1]}\")\n",
    "    print(\"\\n--- Data types ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Memory usage ---\")\n",
    "    print(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2), \"MB\")\n",
    "\n",
    "\n",
    "df_raw = pd.read_csv(\"../../data/merge/Khang/Khang.csv\")\n",
    "inspect_csv(df_raw)\n"
   ],
   "id": "20c298e53714000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CSV OVERVIEW =====\n",
      "Rows    : 778\n",
      "Columns : 15\n",
      "\n",
      "--- Data types ---\n",
      "id                       object\n",
      "Title                    object\n",
      "Type                     object\n",
      "Price_Raw                object\n",
      "Price_Billion           float64\n",
      "Area_m2                 float64\n",
      "District                 object\n",
      "City                     object\n",
      "Address                  object\n",
      "Bedrooms                  int64\n",
      "Toilets                   int64\n",
      "Post_Time                object\n",
      "Link                     object\n",
      "Description              object\n",
      "Price_Per_m2_Million    float64\n",
      "dtype: object\n",
      "\n",
      "--- Memory usage ---\n",
      "2.5 MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "H√†m ki·ªÉm tra v√† th√¥ng b√°o √¥ thi·∫øu d·ªØ li·ªáu theo tung c·ªôt",
   "id": "2c1f9cbe35625d22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:19.386085500Z",
     "start_time": "2026-01-03T11:17:19.370078500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def report_missing_values(df):\n",
    "    print(\"===== MISSING VALUE REPORT =====\")\n",
    "    missing = df.isna().sum()\n",
    "    percent = (missing / len(df)) * 100\n",
    "    report = pd.DataFrame({\n",
    "        \"Missing_Count\": missing,\n",
    "        \"Percent_Missing (%)\": percent.round(2)\n",
    "    }).sort_values(by=\"Missing_Count\", ascending=False)\n",
    "    print(report)\n",
    "    return report\n"
   ],
   "id": "d0407ac1463bd159",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:21.193266400Z",
     "start_time": "2026-01-03T11:17:21.010060600Z"
    }
   },
   "cell_type": "code",
   "source": "report_missing_values(df_raw)",
   "id": "36937fdb1bf82be9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MISSING VALUE REPORT =====\n",
      "                      Missing_Count  Percent_Missing (%)\n",
      "Price_Per_m2_Million             12                 1.54\n",
      "Title                             0                 0.00\n",
      "id                                0                 0.00\n",
      "Price_Raw                         0                 0.00\n",
      "Price_Billion                     0                 0.00\n",
      "Area_m2                           0                 0.00\n",
      "Type                              0                 0.00\n",
      "District                          0                 0.00\n",
      "City                              0                 0.00\n",
      "Bedrooms                          0                 0.00\n",
      "Address                           0                 0.00\n",
      "Toilets                           0                 0.00\n",
      "Post_Time                         0                 0.00\n",
      "Link                              0                 0.00\n",
      "Description                       0                 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                      Missing_Count  Percent_Missing (%)\n",
       "Price_Per_m2_Million             12                 1.54\n",
       "Title                             0                 0.00\n",
       "id                                0                 0.00\n",
       "Price_Raw                         0                 0.00\n",
       "Price_Billion                     0                 0.00\n",
       "Area_m2                           0                 0.00\n",
       "Type                              0                 0.00\n",
       "District                          0                 0.00\n",
       "City                              0                 0.00\n",
       "Bedrooms                          0                 0.00\n",
       "Address                           0                 0.00\n",
       "Toilets                           0                 0.00\n",
       "Post_Time                         0                 0.00\n",
       "Link                              0                 0.00\n",
       "Description                       0                 0.00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Percent_Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price_Per_m2_Million</th>\n",
       "      <td>12</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Raw</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Billion</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Address</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toilets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post_Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:26.653292700Z",
     "start_time": "2026-01-03T11:17:26.593206900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask = df_raw['Post_Time'].isna()\n",
    "\n",
    "mask.sum(), len(df_raw)\n"
   ],
   "id": "bdcfb08f46f99f41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), 778)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:28.352317500Z",
     "start_time": "2026-01-03T11:17:28.273500300Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].dtype\n",
   "id": "adc71e7d648fe738",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:29.553356600Z",
     "start_time": "2026-01-03T11:17:29.487719500Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].value_counts().head(10)\n",
   "id": "158bfcf219c5b884",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Post_Time\n",
       "27/08/2025    54\n",
       "01/09/2025    45\n",
       "02/09/2025    42\n",
       "10/09/2025    23\n",
       "28/08/2025    22\n",
       "15/12/2025    22\n",
       "11/09/2025    20\n",
       "03/09/2025    20\n",
       "25/08/2025    20\n",
       "23/08/2025    17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parse post time ra datatype datetime",
   "id": "8a507ade70500813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:32.093506600Z",
     "start_time": "2026-01-03T11:17:32.063333100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw['Post_Time'] = pd.to_datetime(\n",
    "    df_raw['Post_Time'],\n",
    "    format='%d/%m/%Y',\n",
    "    errors='coerce'\n",
    ")\n"
   ],
   "id": "aca7fbb23a407919",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:33.843068900Z",
     "start_time": "2026-01-03T11:17:33.798248500Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].dtype\n",
   "id": "f5ef27c5c3473e10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:35.103142700Z",
     "start_time": "2026-01-03T11:17:35.023460Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].isna().sum(), len(df_raw)\n",
   "id": "3a3fd6a6430db6ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), 778)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f92435d7857f9ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:18:13.773049700Z",
     "start_time": "2026-01-03T11:18:13.578932600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- C·∫§U H√åNH T√äN FILE ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khang.csv'  # ƒê·∫∑t t√™n file csv c·ªßa b·∫°n l√† data.csv\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone.csv'\n",
    "\n",
    "# --- H√ÄM X·ª¨ L√ù ---\n",
    "def extract_width(row):\n",
    "    # G·ªôp & L√†m s·∫°ch s∆° b·ªô\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "\n",
    "    # --- B∆Ø·ªöC CHU·∫®N H√ìA QUAN TR·ªåNG ---\n",
    "    text = text.replace(',', '.')           # ƒê·ªïi ph·∫©y th√†nh ch·∫•m (6,5 -> 6.5)\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)     # ƒê·ªïi m·ªçi icon nh√¢n th√†nh 'x'\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)    # ƒê·ªïi g·∫°ch n·ªëi d√≠nh ch·ªØ th√†nh kho·∫£ng tr·∫Øng\n",
    "\n",
    "    # M·∫™U 1: C·ª•m \"Chi·ªÅu r·ªông... 77m\" (X·ª≠ l√Ω l·ªói typo)\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50: val = val / 10 # Fix l·ªói 77m -> 7.7m\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 2: T·ª´ kh√≥a \"Ngang\" + t·ª´ ƒë·ªám (kh·ªßng/ƒë·∫πp) + S·ªë\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 3: D·∫°ng k√≠ch th∆∞·ªõc A x B (C√≥ ch·ªØ m ho·∫∑c kh√¥ng)\n",
    "    # T√¨m t·∫•t c·∫£ c√°c c·∫∑p s·ªë d·∫°ng AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2) # L·∫•y s·ªë nh·ªè l√†m chi·ªÅu ngang\n",
    "\n",
    "                # ∆Øu ti√™n: N·∫øu d√≤ng ƒë√≥ c√≥ ch·ªØ 'm' (vd: 6x13m) th√¨ tin lu√¥n\n",
    "                if 'm' in m.group(0) and 2 <= width < 50:\n",
    "                    return width\n",
    "                # N·∫øu kh√¥ng c√≥ 'm' (vd: 4x16), l∆∞u l·∫°i xem x√©t sau\n",
    "                if 2 <= width < 50:\n",
    "                    temp_width = width\n",
    "            except: continue\n",
    "\n",
    "        # N·∫øu ƒë√£ t√¨m th·∫•y d·∫°ng AxB h·ª£p l√Ω\n",
    "        if 'temp_width' in locals(): return temp_width\n",
    "\n",
    "    return None\n",
    "\n",
    "def check_mattien(row):\n",
    "    text = str(row['Title']) + \" \" + str(row['Description'])\n",
    "    text = text.lower()\n",
    "\n",
    "    # 1. DANH S√ÅCH T·ª™ KH√ìA LO·∫†I TR·ª™ (Th·∫•y m·∫•y t·ª´ n√†y l√† bi·∫øt ko ph·∫£i m·∫∑t ti·ªÅn x·ªãn)\n",
    "    # V√≠ d·ª•: \"s√°t m·∫∑t ti·ªÅn\", \"c√°ch m·∫∑t ti·ªÅn\", \"g·∫ßn m·∫∑t ti·ªÅn\", \"h·∫ªm xe h∆°i quay ƒë·∫ßu\"\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text:\n",
    "            return 0 # G·∫∑p t·ª´ 's√°t'/'c√°ch' -> Tr·∫£ v·ªÅ 0 ngay l·∫≠p t·ª©c (L√† h·∫ªm)\n",
    "\n",
    "    # 2. DANH S√ÅCH T·ª™ KH√ìA NH·∫¨N DI·ªÜN M·∫∂T TI·ªÄN (Sau khi ƒë√£ l·ªçc b·ªçn 's√°t/g·∫ßn')\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text:\n",
    "            return 1 # C√≥ m·∫∑t ti·ªÅn\n",
    "\n",
    "    return 0 # Kh√¥ng th·∫•y g√¨ -> M·∫∑c ƒë·ªãnh l√† h·∫ªm\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "\n",
    "try:\n",
    "    # 1. ƒê·ªçc file v·ªõi ƒë√∫ng c√°c c·ªôt b·∫°n cung c·∫•p\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # 2. X·ª≠ l√Ω chi·ªÅu ngang (Width_m)\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # 3. X·ª≠ l√Ω M·∫∑t ti·ªÅn (Is_MatTien)\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # 4. T√≠nh ƒê∆°n gi√° (Price_Per_m2) = (T·ª∑ * 1000) / m2\n",
    "    # Ch·ªâ t√≠nh khi Di·ªán t√≠ch > 0 ƒë·ªÉ tr√°nh l·ªói chia cho 0\n",
    "    df['Price_Per_m2'] = df.apply(\n",
    "        lambda x: round((x['Price_Billion'] * 1000) / x['Area_m2'], 2)\n",
    "        if x['Area_m2'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 5. L∆∞u file\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Xong! File k·∫øt qu·∫£ l√†: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 30)\n",
    "    # In th·ª≠ 5 d√≤ng c√°c c·ªôt quan tr·ªçng ƒë·ªÉ ki·ªÉm tra\n",
    "    print(df[['id', 'Title', 'Width_m', 'Is_MatTien', 'Price_Per_m2']].head().to_string())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. H√£y ch·∫Øc ch·∫Øn file n·∫±m c√πng th∆∞ m·ª•c v·ªõi code.\")"
   ],
   "id": "d9741413d20427be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "Xong! File k·∫øt qu·∫£ l√†: ../../data/merge/Khang/Khangdone.csv\n",
      "------------------------------\n",
      "                                     id                                                                                Title  Width_m  Is_MatTien  Price_Per_m2\n",
      "0  77d338cb-abbc-43e3-9a99-eb76c22adb3f                               Nh√† MT ƒë∆∞·ªùng s·ªë ph∆∞·ªùng Ch√°nh H∆∞ng. Gi√° 5,28 t·ª∑ b·ªõt l·ªôc     3.00           1        128.78\n",
      "1  34c726fa-59ca-4aaf-91db-683839fea1f8           BaÃÅn nhaÃÄ mƒÉÃ£t ti√™ÃÄn 3 t√¢ÃÄng 6.6x28m giaÃÅ 16,99 tyÃâ ƒê∆∞∆°ÃÄng Tr∆∞∆°ng ThiÃ£ Hoa     5.00           0        212.38\n",
      "2  67f9febf-cb8c-4b74-af77-0018eeced7d9                                      B√°n nh√† m·∫∑t ti·ªÅn th·ª•t L√™ VƒÉn S·ªπ, 79m2, ch·ªâ 8 t·ª∑      NaN           1        101.27\n",
      "3  ca3d7226-45b1-4fb6-a698-536bc479f744                                Nh√† M·∫∑t ti·ªÅn ƒë∆∞·ªùng Phong Ph√∫ - P11, Gi√° : 5,6 T·ªâ (TL)     2.90           1        127.27\n",
      "4  d9206372-26a0-4aab-bd05-41807c8162e0  TRUNG T√ÇM QU·∫¨N 9 ‚Äì SI√äU PH·∫®M M·∫∂T TI·ªÄN L√É XU√ÇN OAI ‚Äì 198M¬≤ ‚Äì 2 T·∫¶NG BTCT ‚Äì GI√Å 24 T·ª∂     7.48           1        121.21\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xu·∫•t data m√† 1 trong c√°c tr∆∞·ªùng Toilets,Bedrooms,  Price_Billion,Price_Per_m2 ,Area_m2  b·ªã thi·∫øu",
   "id": "3a9784a7825b5dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:18:24.067437100Z",
     "start_time": "2026-01-03T11:18:24.006379300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone.csv'  # File d·ªØ li·ªáu s·∫°ch t·ª´ b∆∞·ªõc tr∆∞·ªõc\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone1.csv'  # File ch·ª©a c√°c d√≤ng b·ªã l·ªói\n",
    "\n",
    "try:\n",
    "    print(f\"ƒêang ƒë·ªçc file {INPUT_FILE}...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # Danh s√°ch c√°c c·ªôt c·∫ßn ki·ªÉm tra\n",
    "    check_cols = ['Address']\n",
    "\n",
    "    # L·ªçc c√°c d√≤ng c√≥ √≠t nh·∫•t 1 √¥ b·ªã Null trong danh s√°ch c·ªôt tr√™n\n",
    "    # how='any' nghƒ©a l√† ch·ªâ c·∫ßn 1 c·ªôt b·ªã thi·∫øu l√† l·∫•y ra\n",
    "    df_missing = df[df[check_cols].isnull().any(axis=1)]\n",
    "\n",
    "    # L∆∞u ra file m·ªõi\n",
    "    df_missing.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"X·ª¨ L√ù XONG!\")\n",
    "    print(f\"T·ªïng s·ªë d√≤ng b·ªã thi·∫øu th√¥ng tin: {len(df_missing)} d√≤ng\")\n",
    "    print(f\"ƒê√£ xu·∫•t d·ªØ li·ªáu ra file: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # In th·ªëng k√™ chi ti·∫øt l·∫°i m·ªôt l·∫ßn n·ªØa cho t·∫≠p d·ªØ li·ªáu n√†y\n",
    "    print(\"Chi ti·∫øt s·ªë l∆∞·ª£ng thi·∫øu trong file n√†y:\")\n",
    "    print(df_missing[check_cols].isnull().sum())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y code t·∫°o file data_clean_final.csv ·ªü b∆∞·ªõc tr∆∞·ªõc.\")\n",
    "except KeyError as e:\n",
    "    print(f\"L·ªói: File thi·∫øu c·ªôt {e}. H√£y ki·ªÉm tra l·∫°i t√™n c·ªôt trong file CSV.\")"
   ],
   "id": "d6ca4e69ab1db025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang ƒë·ªçc file ../../data/merge/Khang/Khangdone.csv...\n",
      "----------------------------------------\n",
      "X·ª¨ L√ù XONG!\n",
      "T·ªïng s·ªë d√≤ng b·ªã thi·∫øu th√¥ng tin: 0 d√≤ng\n",
      "ƒê√£ xu·∫•t d·ªØ li·ªáu ra file: ../../data/merge/Khang/Khangdone1.csv\n",
      "----------------------------------------\n",
      "Chi ti·∫øt s·ªë l∆∞·ª£ng thi·∫øu trong file n√†y:\n",
      "Address    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "D·ª±a k·∫øt qu·∫£ l·ªçc width t√¨m l·∫°i tr∆∞·ªùng Area_m2 b·ªã tr·ªëng, t√≠nh l·∫°i s·ªë ti·ªÅn tr√™n m·ªói m2",
   "id": "dcd412c2e389cdfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:18:31.983045100Z",
     "start_time": "2026-01-03T11:18:31.722958300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone2.csv'\n",
    "\n",
    "# ================= 1. GI·ªÆ NGUY√äN H√ÄM C·ª¶A B·∫†N (ƒê√£ t·ªëi ∆∞u) =================\n",
    "def extract_width(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    # M·∫™U 1: Chi·ªÅu r·ªông...\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50: val = val / 10\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 2: Ngang...\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 3: AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2)\n",
    "                if 'm' in m.group(0) and 2 <= width < 50: return width\n",
    "                if 2 <= width < 50: temp_width = width\n",
    "            except: continue\n",
    "        if 'temp_width' in locals(): return temp_width\n",
    "    return None\n",
    "\n",
    "def check_mattien(row):\n",
    "    text = str(row['Title']) + \" \" + str(row['Description'])\n",
    "    text = text.lower()\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text: return 0\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text: return 1\n",
    "    return 0\n",
    "\n",
    "# ================= 2. H√ÄM M·ªöI: T√åM CHI·ªÄU D√ÄI & T√çNH DI·ªÜN T√çCH =================\n",
    "def recover_missing_area(row):\n",
    "    # N·∫øu Di·ªán t√≠ch ƒë√£ c√≥ d·ªØ li·ªáu h·ª£p l·ªá (>0) th√¨ gi·ªØ nguy√™n, kh√¥ng c·∫ßn t√≠nh l·∫°i\n",
    "    current_area = row.get('Area_m2', 0)\n",
    "    if pd.notnull(current_area) and current_area > 0:\n",
    "        return current_area\n",
    "\n",
    "    # N·∫øu kh√¥ng c√≥ Chi·ªÅu Ngang (Width), th√¨ ch·ªãu thua, kh√¥ng t√≠nh ƒë∆∞·ª£c Area\n",
    "    width = row.get('Width_m')\n",
    "    if pd.isnull(width) or width == 0:\n",
    "        return current_area # Tr·∫£ v·ªÅ nh∆∞ c≈© (Null ho·∫∑c 0)\n",
    "\n",
    "    # --- B·∫ÆT ƒê·∫¶U ƒêI T√åM CHI·ªÄU D√ÄI (LENGTH) ---\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    length = None\n",
    "\n",
    "    # M·∫™U A: T√¨m t·ª´ kh√≥a \"D√†i...\" (V√≠ d·ª•: Ngang 5 d√†i 20)\n",
    "    match_dai = re.search(r'd√†i\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match_dai:\n",
    "        try:\n",
    "            val = float(match_dai.group(1))\n",
    "            # Chi·ªÅu d√†i th∆∞·ªùng ph·∫£i l·ªõn h∆°n chi·ªÅu r·ªông v√† < 100m (nh√† ph·ªë)\n",
    "            if val >= width and val < 150:\n",
    "                length = val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U B: T√¨m trong c·ª•m AxB (V√≠ d·ª•: 5x20)\n",
    "    # Logic: N·∫øu Width kh·ªõp v·ªõi 1 trong 2 s·ªë, th√¨ s·ªë kia l√† Length\n",
    "    if length is None:\n",
    "        matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                # N·∫øu 1 trong 2 s·ªë x·∫•p x·ªâ b·∫±ng Width m√† m√¨nh ƒë√£ t√¨m ra\n",
    "                # (Cho sai s·ªë 0.1 ph√≤ng tr∆∞·ªùng h·ª£p l√†m tr√≤n)\n",
    "                if abs(n1 - width) < 0.1: length = n2\n",
    "                elif abs(n2 - width) < 0.1: length = n1\n",
    "\n",
    "                if length: break\n",
    "            except: continue\n",
    "\n",
    "    # --- T√çNH TO√ÅN DI·ªÜN T√çCH ---\n",
    "    if length and length > 0:\n",
    "        calculated_area = width * length\n",
    "        return round(calculated_area, 2)\n",
    "\n",
    "    return current_area # Kh√¥ng t√¨m th·∫•y Length th√¨ tr·∫£ v·ªÅ Null nh∆∞ c≈©\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t Width (nh∆∞ c≈©)\n",
    "    print(\"- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang...\")\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 2: C·ª®U D·ªÆ LI·ªÜU AREA (B∆∞·ªõc m·ªõi)\n",
    "    # L·∫•p ƒë·∫ßy c√°c √¥ Area b·ªã tr·ªëng b·∫±ng c√°ch t√≠nh Width * Length\n",
    "    print(\"- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\")\n",
    "    df['Area_m2'] = df.apply(recover_missing_area, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·∫∑t ti·ªÅn\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 4: T√≠nh l·∫°i ƒë∆°n gi√° (Sau khi ƒë√£ c·ª©u ƒë∆∞·ª£c Area)\n",
    "    df['Price_Per_m2'] = df.apply(\n",
    "        lambda x: round((x['Price_Billion'] * 1000) / x['Area_m2'], 2)\n",
    "        if pd.notnull(x['Area_m2']) and x['Area_m2'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Xong! File k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # In ki·ªÉm tra nh·ªØng d√≤ng m√† Area ƒë∆∞·ª£c c·ª©u s·ªëng (tr∆∞·ªõc ƒë√≥ l√† null/0 nh∆∞ng gi·ªù c√≥ Width*Length)\n",
    "    # Logic in: C√≥ Width, C√≥ Area, nh∆∞ng Price_Raw c√≥ th·ªÉ check sau\n",
    "    print(\"M·∫´u 5 d√≤ng d·ªØ li·ªáu sau khi t√≠nh to√°n:\")\n",
    "    print(df[['id', 'Width_m', 'Area_m2', 'Price_Per_m2']].head(10).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói: {e}\")"
   ],
   "id": "c72405e0e2fda10a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang...\n",
      "- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\n",
      "Xong! File k·∫øt qu·∫£: ../../data/merge/Khang/Khangdone2.csv\n",
      "------------------------------\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu sau khi t√≠nh to√°n:\n",
      "                                     id  Width_m  Area_m2  Price_Per_m2\n",
      "0  77d338cb-abbc-43e3-9a99-eb76c22adb3f     3.00     41.0        128.78\n",
      "1  34c726fa-59ca-4aaf-91db-683839fea1f8     5.00     80.0        212.38\n",
      "2  67f9febf-cb8c-4b74-af77-0018eeced7d9      NaN     79.0        101.27\n",
      "3  ca3d7226-45b1-4fb6-a698-536bc479f744     2.90     44.0        127.27\n",
      "4  d9206372-26a0-4aab-bd05-41807c8162e0     7.48    198.0        121.21\n",
      "5  701f4eb9-7df4-45aa-898d-2f3b100695a4     4.00     80.0        150.00\n",
      "6  873fd28b-f0e3-4078-8efa-a0033a1e5720     5.00     80.0        128.75\n",
      "7  329561bc-8bbb-48c1-88d7-2aa4ca485235     6.00    120.0        154.17\n",
      "8  f4aa3194-1899-42de-a1a4-5c9220e430dc     5.00     90.0        214.44\n",
      "9  4b0a98c1-3b68-48c8-8799-582fb7774482     5.34     62.0        179.03\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tr√≠ch xu·∫•t b·ªï sung th√™m t∆∞·ªùng Floors c·∫£i ti·∫øn code tr√™n",
   "id": "421a6a0ca11cd12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:18:45.706707900Z",
     "start_time": "2026-01-03T11:18:45.467698200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# H√£y ƒë·∫£m b·∫£o t√™n file INPUT ƒë√∫ng v·ªõi file b·∫°n ƒëang c√≥\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone2.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone3.csv'\n",
    "\n",
    "# ================= 1. H√ÄM TR√çCH XU·∫§T CHI·ªÄU NGANG (WIDTH) =================\n",
    "def extract_width(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    # M·∫™U 1: Chi·ªÅu r·ªông...\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50: val = val / 10\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 2: Ngang...\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 3: AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2)\n",
    "                if 'm' in m.group(0) and 2 <= width < 50: return width\n",
    "                if 2 <= width < 50: temp_width = width\n",
    "            except: continue\n",
    "        if 'temp_width' in locals(): return temp_width\n",
    "    return None\n",
    "\n",
    "# ================= 2. H√ÄM X√ÅC ƒê·ªäNH M·∫∂T TI·ªÄN =================\n",
    "def check_mattien(row):\n",
    "    text = str(row['Title']) + \" \" + str(row['Description'])\n",
    "    text = text.lower()\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text: return 0\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text: return 1\n",
    "    return 0\n",
    "\n",
    "# ================= 3. H√ÄM T√çNH TO√ÅN L·∫†I DI·ªÜN T√çCH =================\n",
    "def recover_missing_area(row):\n",
    "    current_area = row.get('Area_m2', 0)\n",
    "    if pd.notnull(current_area) and current_area > 0:\n",
    "        return current_area\n",
    "\n",
    "    width = row.get('Width_m')\n",
    "    if pd.isnull(width) or width == 0:\n",
    "        return current_area\n",
    "\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    length = None\n",
    "    # M·∫™U A: T√¨m t·ª´ kh√≥a \"D√†i...\"\n",
    "    match_dai = re.search(r'd√†i\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match_dai:\n",
    "        try:\n",
    "            val = float(match_dai.group(1))\n",
    "            if val >= width and val < 150:\n",
    "                length = val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U B: T√¨m trong c·ª•m AxB\n",
    "    if length is None:\n",
    "        matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                if abs(n1 - width) < 0.1: length = n2\n",
    "                elif abs(n2 - width) < 0.1: length = n1\n",
    "                if length: break\n",
    "            except: continue\n",
    "\n",
    "    if length and length > 0:\n",
    "        return round(width * length, 2)\n",
    "    return current_area\n",
    "\n",
    "# ================= 4. H√ÄM TR√çCH XU·∫§T S·ªê T·∫¶NG (FLOORS) - M·ªöI! =================\n",
    "def extract_floors(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace('t·∫•m', 't·∫ßng') # Chu·∫©n h√≥a\n",
    "\n",
    "    floors = 0\n",
    "    found_sDatture = False\n",
    "\n",
    "    # 4.1 Chi·∫øn thu·∫≠t c·ªông d·ªìn: Tr·ªát + L·∫ßu + L·ª≠ng + S√¢n th∆∞·ª£ng\n",
    "    matches_lau = re.findall(r'(\\d+)\\s*l·∫ßu', text)\n",
    "    if matches_lau:\n",
    "        num_lau = max([float(x) for x in matches_lau])\n",
    "        floors = num_lau + 1 # +1 cho t·∫ßng tr·ªát\n",
    "        found_sDatture = True\n",
    "    elif 'tr·ªát' in text and 'l·∫ßu' in text:\n",
    "        floors = 2 # M·∫∑c ƒë·ªãnh 1 tr·ªát 1 l·∫ßu\n",
    "        found_sDatture = True\n",
    "\n",
    "    if found_sDatture:\n",
    "        if 'l·ª≠ng' in text: floors += 0.5\n",
    "        if 's√¢n th∆∞·ª£ng' in text or 'chu·ªìng cu' in text or 'tum' in text: floors += 0.5\n",
    "        return floors\n",
    "\n",
    "    # 4.2 Chi·∫øn thu·∫≠t t√¨m s·ªë t·ªïng: \"3 t·∫ßng\", \"4 t·∫•m\"\n",
    "    match_tang = re.search(r'(\\d+)\\s*t·∫ßng', text)\n",
    "    if match_tang:\n",
    "        return float(match_tang.group(1))\n",
    "\n",
    "    # 4.3 C√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát\n",
    "    if 'c·∫•p 4' in text or 'cap 4' in text: return 1.0\n",
    "    if 'g√°c' in text: return 1.5\n",
    "\n",
    "    return 1.0 # M·∫∑c ƒë·ªãnh b√®o nh·∫•t l√† 1 t·∫ßng\n",
    "\n",
    "# ================= CH·∫†Y CH∆Ø∆†NG TR√åNH =================\n",
    "print(\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t Width\n",
    "    print(\"- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang (Width)...\")\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 2: C·ª®U D·ªÆ LI·ªÜU AREA\n",
    "    print(\"- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\")\n",
    "    df['Area_m2'] = df.apply(recover_missing_area, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·∫∑t ti·ªÅn\n",
    "    print(\"- ƒêang x√°c ƒë·ªãnh M·∫∑t ti·ªÅn (Is_MatTien)...\")\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 4: Tr√≠ch xu·∫•t s·ªë t·∫ßng (M·ªöI)\n",
    "    print(\"- ƒêang ƒë·ªçc k·∫øt c·∫•u s·ªë t·∫ßng (Floors)...\")\n",
    "    df['Floors'] = df.apply(extract_floors, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 5: T√≠nh l·∫°i ƒë∆°n gi√°\n",
    "    print(\"- ƒêang c·∫≠p nh·∫≠t ƒë∆°n gi√° (Price_Per_m2)...\")\n",
    "    df['Price_Per_m2'] = df.apply(\n",
    "        lambda x: round((x['Price_Billion'] * 1000) / x['Area_m2'], 2)\n",
    "        if pd.notnull(x['Area_m2']) and x['Area_m2'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"‚úÖ XONG! File k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # In ki·ªÉm tra m·∫´u\n",
    "    print(\"M·∫´u 5 d√≤ng d·ªØ li·ªáu (Width, Area, Floors, Price/m2):\")\n",
    "    print(df[['id', 'Width_m', 'Area_m2', 'Floors', 'Price_Per_m2']].head(10).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói: {e}\")"
   ],
   "id": "b6c394826c5e3f4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang (Width)...\n",
      "- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\n",
      "- ƒêang x√°c ƒë·ªãnh M·∫∑t ti·ªÅn (Is_MatTien)...\n",
      "- ƒêang ƒë·ªçc k·∫øt c·∫•u s·ªë t·∫ßng (Floors)...\n",
      "- ƒêang c·∫≠p nh·∫≠t ƒë∆°n gi√° (Price_Per_m2)...\n",
      "------------------------------\n",
      "‚úÖ XONG! File k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß: ../../data/merge/Khang/Khangdone3.csv\n",
      "------------------------------\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu (Width, Area, Floors, Price/m2):\n",
      "                                     id  Width_m  Area_m2  Floors  Price_Per_m2\n",
      "0  77d338cb-abbc-43e3-9a99-eb76c22adb3f     3.00     41.0     3.0        128.78\n",
      "1  34c726fa-59ca-4aaf-91db-683839fea1f8     5.00     80.0     3.5        212.38\n",
      "2  67f9febf-cb8c-4b74-af77-0018eeced7d9      NaN     79.0     1.0        101.27\n",
      "3  ca3d7226-45b1-4fb6-a698-536bc479f744     2.90     44.0     2.0        127.27\n",
      "4  d9206372-26a0-4aab-bd05-41807c8162e0     7.48    198.0     2.0        121.21\n",
      "5  701f4eb9-7df4-45aa-898d-2f3b100695a4     4.00     80.0     3.0        150.00\n",
      "6  873fd28b-f0e3-4078-8efa-a0033a1e5720     5.00     80.0     4.0        128.75\n",
      "7  329561bc-8bbb-48c1-88d7-2aa4ca485235     6.00    120.0     5.0        154.17\n",
      "8  f4aa3194-1899-42de-a1a4-5c9220e430dc     5.00     90.0     4.0        214.44\n",
      "9  4b0a98c1-3b68-48c8-8799-582fb7774482     5.34     62.0     1.0        179.03\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc Thi·∫øu Price_Per_m2, Thi·∫øu District, Gi√° qu√° r·∫ª (< 500 tri·ªáu), Width_m, tr√πng l·∫∑p, ƒêi·ªÅn khuy·∫øt th√¥ng minh: T·ª± ƒë·ªông t√≠nh Median s·ªë ph√≤ng ng·ªß/toilet c·ªßa t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn v√†o ch·ªó tr·ªëng c·ªßa Qu·∫≠n ƒë√≥.",
   "id": "6fb64e879ae9db89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:18:54.770534100Z",
     "start_time": "2026-01-03T11:18:54.672970100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# Input l√† file ƒë√£ t√≠nh to√°n xong ·ªü b∆∞·ªõc tr∆∞·ªõc\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone3.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone4.csv'\n",
    "\n",
    "try:\n",
    "    print(\"‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    n_original = len(df)\n",
    "    print(f\"--> T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: {n_original}\")\n",
    "\n",
    "    # ================= B∆Ø·ªöC 1: THANH L·ªåC D·ªÆ LI·ªÜU (FILTERING) =================\n",
    "\n",
    "    # 1.1 X√≥a c√°c d√≤ng b·ªã thi·∫øu th√¥ng tin CH√ç M·∫†NG (Critical Missing)\n",
    "    # Th√™m 'Area_m2' v√†o ƒë√¢y ƒë·ªÉ lo·∫°i b·ªè ngay 49 d√≤ng b·ªã l·ªói di·ªán t√≠ch\n",
    "    critical_cols = ['Price_Per_m2', 'District', 'Width_m', 'Area_m2']\n",
    "    df = df.dropna(subset=critical_cols)\n",
    "\n",
    "    # L·ªçc th√™m: ƒê·∫£m b·∫£o ƒë∆°n gi√° ph·∫£i > 0 (tr√°nh l·ªói chia cho 0 c√≤n s√≥t)\n",
    "    df = df[df['Price_Per_m2'] > 0]\n",
    "\n",
    "    print(f\"- Sau khi x√≥a thi·∫øu Gi√°/Qu·∫≠n/Chi·ªÅu ngang/Di·ªán t√≠ch: {len(df)}\")\n",
    "\n",
    "    # 1.2 L·ªçc theo Gi√° tr·ªã (Price Billion)\n",
    "    # Y√™u c·∫ßu: Gi√° qu√° r·∫ª (< 500 tri·ªáu hay 0.5 t·ª∑) -> X√ìA\n",
    "    df = df[df['Price_Billion'] >= 0.5]\n",
    "    print(f\"- Sau khi x√≥a nh√† < 500 tri·ªáu: {len(df)}\")\n",
    "\n",
    "    # 1.3 X·ª≠ l√Ω tr√πng l·∫∑p (Duplicates)\n",
    "    # Logic: N·∫øu Ti√™u ƒë·ªÅ, Gi√°, Di·ªán t√≠ch v√† Qu·∫≠n gi·ªëng h·ªát nhau -> Coi l√† spam -> X√ìA\n",
    "    df = df.drop_duplicates(subset=['Title', 'Price_Billion', 'Area_m2', 'District'])\n",
    "    print(f\"- Sau khi x√≥a tin Spam tr√πng l·∫∑p: {len(df)}\")\n",
    "\n",
    "    # *L∆ØU √ù: C√°c ƒëi·ªÅu ki·ªán Di·ªán t√≠ch <10, >500, Gi√° ·∫£o >800 -> KH√îNG L·ªåC (Theo y√™u c·∫ßu)*\n",
    "\n",
    "    # ================= B∆Ø·ªöC 2: ƒêI·ªÄN KHUY·∫æT TH√îNG MINH (GROUP IMPUTATION) =================\n",
    "    # Y√™u c·∫ßu: D√πng Median (Trung v·ªã) c·ªßa t·ª´ng QU·∫¨N ƒë·ªÉ ƒëi·ªÅn v√†o Bedrooms/Toilets b·ªã thi·∫øu\n",
    "\n",
    "    print(\"\\n‚è≥ ƒêang t√≠nh to√°n Median theo t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn khuy·∫øt...\")\n",
    "\n",
    "    # H√†m ƒëi·ªÅn median theo nh√≥m\n",
    "    def fill_na_with_district_median(df, target_col, group_col='District'):\n",
    "        # T√≠nh median cho t·ª´ng nh√≥m (Qu·∫≠n)\n",
    "        median_series = df.groupby(group_col)[target_col].transform('median')\n",
    "\n",
    "        # ƒêi·ªÅn c√°c √¥ NaN b·∫±ng gi√° tr·ªã median v·ª´a t√≠nh\n",
    "        df[target_col] = df[target_col].fillna(median_series)\n",
    "\n",
    "        # \"Ch·ªØa ch√°y\": N·∫øu c·∫£ Qu·∫≠n ƒë√≥ kh√¥ng c√≥ d·ªØ li·ªáu n√†o (hi·∫øm), d√πng Median to√†n th√†nh ph·ªë\n",
    "        global_median = df[target_col].median()\n",
    "        df[target_col] = df[target_col].fillna(global_median)\n",
    "\n",
    "        # L√†m tr√≤n s·ªë (v√¨ ph√≤ng ng·ªß/toilet ph·∫£i l√† s·ªë nguy√™n)\n",
    "        df[target_col] = df[target_col].round()\n",
    "        return df\n",
    "\n",
    "    # Th·ª±c hi·ªán ƒëi·ªÅn cho Bedrooms & Toilets\n",
    "    df = fill_na_with_district_median(df, 'Bedrooms')\n",
    "    df = fill_na_with_district_median(df, 'Toilets')\n",
    "\n",
    "        # ================= B∆Ø·ªöC 3: KI·ªÇM TRA CU·ªêI C√ôNG & L∆ØU FILE =================\n",
    "\n",
    "    print(\"\\n‚è≥ ƒêang l∆∞u file k·∫øt qu·∫£...\")\n",
    "\n",
    "    # L∆∞u file CSV\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU\")\n",
    "    print(f\"üìÅ File k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "    print(f\"üìä S·ªë l∆∞·ª£ng d√≤ng c√≤n l·∫°i: {len(df)} \"\n",
    "          f\"(Gi·ªØ l·∫°i {round(len(df)/n_original*100, 1)}% d·ªØ li·ªáu g·ªëc)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ================= DEMO PH·ª§C V·ª§ B√ÅO C√ÅO =================\n",
    "    print(\"\\n[Demo B√°o C√°o] Ki·ªÉm tra d·ªØ li·ªáu Qu·∫≠n G√≤ V·∫•p sau khi ƒëi·ªÅn Median:\")\n",
    "\n",
    "    sample = df[df['District'].str.contains('G√≤ V·∫•p', na=False, case=False)]\n",
    "    if not sample.empty:\n",
    "        print(sample[['District', 'Bedrooms', 'Toilets']].head(5).to_string())\n",
    "    else:\n",
    "        print(\"(Kh√¥ng c√≥ d·ªØ li·ªáu G√≤ V·∫•p ‚Äì in 5 d√≤ng b·∫•t k·ª≥)\")\n",
    "        print(df[['District', 'Bedrooms', 'Toilets']].head(5).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå C√ì L·ªñI X·∫¢Y RA TRONG QU√Å TR√åNH X·ª¨ L√ù!\")\n",
    "    print(f\"üëâ Chi ti·∫øt l·ªói: {e}\")\n"
   ],
   "id": "fa265f5a35219d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu...\n",
      "--> T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: 778\n",
      "- Sau khi x√≥a thi·∫øu Gi√°/Qu·∫≠n/Chi·ªÅu ngang/Di·ªán t√≠ch: 665\n",
      "- Sau khi x√≥a nh√† < 500 tri·ªáu: 662\n",
      "- Sau khi x√≥a tin Spam tr√πng l·∫∑p: 557\n",
      "\n",
      "‚è≥ ƒêang t√≠nh to√°n Median theo t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn khuy·∫øt...\n",
      "\n",
      "‚è≥ ƒêang l∆∞u file k·∫øt qu·∫£...\n",
      "--------------------------------------------------\n",
      "‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
      "üìÅ File k·∫øt qu·∫£: ../../data/merge/Khang/Khangdone4.csv\n",
      "üìä S·ªë l∆∞·ª£ng d√≤ng c√≤n l·∫°i: 557 (Gi·ªØ l·∫°i 71.6% d·ªØ li·ªáu g·ªëc)\n",
      "--------------------------------------------------\n",
      "\n",
      "[Demo B√°o C√°o] Ki·ªÉm tra d·ªØ li·ªáu Qu·∫≠n G√≤ V·∫•p sau khi ƒëi·ªÅn Median:\n",
      "        District  Bedrooms  Toilets\n",
      "8    Qu·∫≠n G√≤ V·∫•p         4        4\n",
      "90   Qu·∫≠n G√≤ V·∫•p         3        2\n",
      "132  Qu·∫≠n G√≤ V·∫•p         3        4\n",
      "140  Qu·∫≠n G√≤ V·∫•p         2        0\n",
      "177  Qu·∫≠n G√≤ V·∫•p         4        2\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "T·ª´ title + description => ph∆∞·ªùng(ward)",
   "id": "b2f5a65d6f854c89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:19:21.000939600Z",
     "start_time": "2026-01-03T11:19:20.892051300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone4.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone5.csv'\n",
    "\n",
    "# 1. T·ª™ ƒêI·ªÇN PH∆Ø·ªúNG/X√É (ƒê√£ t√°ch ri√™ng Q2, Q9, Th·ªß ƒê·ª©c ƒë·ªÉ chu·∫©n x√°c h∆°n)\n",
    "hcm_wards_advanced = {\n",
    "    'Qu·∫≠n 1': ['B·∫øn Ngh√©', 'B·∫øn Th√†nh', 'C√¥ Giang', 'C·∫ßu Kho', 'C·∫ßu √îng L√£nh', 'ƒêa Kao', 'Nguy·ªÖn C∆∞ Trinh', 'Nguy·ªÖn Th√°i B√¨nh', 'Ph·∫°m Ng≈© L√£o', 'T√¢n ƒê·ªãnh'],\n",
    "    'Qu·∫≠n 3': ['1', '2', '3', '4', '5', '9', '10', '11', '12', '14', 'V√µ Th·ªã S√°u', '6', '7', '8'],\n",
    "    'Qu·∫≠n 4': ['1', '2', '3', '4', '6', '8', '9', '10', '13', '14', '15', '16', '18', '12'],\n",
    "    'Qu·∫≠n 5': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'],\n",
    "    'Qu·∫≠n 6': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
    "    'Qu·∫≠n 7': ['B√¨nh Thu·∫≠n', 'Ph√∫ M·ªπ', 'Ph√∫ Thu·∫≠n', 'T√¢n H∆∞ng', 'T√¢n Ki·ªÉng', 'T√¢n Phong', 'T√¢n Ph√∫', 'T√¢n Quy', 'T√¢n Thu·∫≠n ƒê√¥ng', 'T√¢n Thu·∫≠n T√¢y'],\n",
    "    'Qu·∫≠n 8': ['1', '2', '3', '4', '5', '6', '8', '7', '9', '10', '11', '12', '13', '14', '15', '16'],\n",
    "    'Qu·∫≠n 10': ['1', '2', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '3'],\n",
    "    'Qu·∫≠n 11': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'],\n",
    "    'Qu·∫≠n 12': ['An Ph√∫ ƒê√¥ng', 'ƒê√¥ng H∆∞ng Thu·∫≠n', 'Hi·ªáp Th√†nh', 'T√¢n Ch√°nh Hi·ªáp', 'T√¢n H∆∞ng Thu·∫≠n', 'T√¢n Th·ªõi Hi·ªáp', 'T√¢n Th·ªõi Nh·∫•t', 'Th·∫°nh L·ªôc', 'Th·∫°nh Xu√¢n', 'Th·ªõi An', 'Trung M·ªπ T√¢y'],\n",
    "    'B√¨nh Th·∫°nh': ['1', '2', '3', '5', '6', '7', '11', '12', '13', '14', '15', '17', '19', '21', '22', '24', '25', '26', '27', '28'],\n",
    "    'G√≤ V·∫•p': ['1', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17'],\n",
    "    'Ph√∫ Nhu·∫≠n': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11', '13', '15', '17'],\n",
    "    'T√¢n B√¨nh': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'],\n",
    "    'T√¢n Ph√∫': ['Hi·ªáp T√¢n', 'H√≤a Th·∫°nh', 'Ph√∫ Th·ªç H√≤a', 'Ph√∫ Th·∫°nh', 'Ph√∫ Trung', 'S∆°n K·ª≥', 'T√¢n Qu√Ω', 'T√¢n S∆°n Nh√¨', 'T√¢n Th√†nh', 'T√¢n Th·ªõi H√≤a', 'T√¢y Th·∫°nh'],\n",
    "    'B√¨nh T√¢n': ['An L·∫°c', 'An L·∫°c A', 'B√¨nh H∆∞ng H√≤a', 'B√¨nh H∆∞ng H√≤a A', 'B√¨nh H∆∞ng H√≤a B', 'B√¨nh Tr·ªã ƒê√¥ng', 'B√¨nh Tr·ªã ƒê√¥ng A', 'B√¨nh Tr·ªã ƒê√¥ng B', 'T√¢n T·∫°o', 'T√¢n T·∫°o A'],\n",
    "\n",
    "    # Khu v·ª±c TP Th·ªß ƒê·ª©c (T√°ch ra ƒë·ªÉ ch√≠nh x√°c)\n",
    "    'Th·ªß ƒê·ª©c': ['B√¨nh Chi·ªÉu', 'B√¨nh Th·ªç', 'Hi·ªáp B√¨nh Ch√°nh', 'Hi·ªáp B√¨nh Ph∆∞·ªõc', 'Linh Chi·ªÉu', 'Linh ƒê√¥ng', 'Linh T√¢y', 'Linh Trung', 'Linh Xu√¢n', 'Tam B√¨nh', 'Tam Ph√∫', 'Tr∆∞·ªùng Th·ªç'],\n",
    "    'Qu·∫≠n 2': ['An Kh√°nh', 'An L·ª£i ƒê√¥ng', 'An Ph√∫', 'B√¨nh An', 'B√¨nh Kh√°nh', 'B√¨nh Tr∆∞ng ƒê√¥ng', 'B√¨nh Tr∆∞ng T√¢y', 'C√°t L√°i', 'Th·∫°nh M·ªπ L·ª£i', 'Th·∫£o ƒêi·ªÅn', 'Th·ªß Thi√™m'],\n",
    "    'Qu·∫≠n 9': ['Hi·ªáp Ph√∫', 'Long B√¨nh', 'Long Ph∆∞·ªõc', 'Long Th·∫°nh M·ªπ', 'Long Tr∆∞·ªùng', 'Ph√∫ H·ªØu', 'Ph∆∞·ªõc B√¨nh', 'Ph∆∞·ªõc Long A', 'Ph∆∞·ªõc Long B', 'T√¢n Ph√∫', 'TƒÉng Nh∆°n Ph√∫ A', 'TƒÉng Nh∆°n Ph√∫ B'],\n",
    "\n",
    "    # Huy·ªán\n",
    "    'C·ªß Chi': ['An Nh∆°n T√¢y', 'B√¨nh M·ªπ', 'H√≤a Ph√∫', 'Nhu·∫≠n ƒê·ª©c', 'Ph·∫°m VƒÉn C·ªôi', 'Ph√∫ H√≤a ƒê√¥ng', 'Ph√∫ M·ªπ H∆∞ng', 'Ph∆∞·ªõc Hi·ªáp', 'Ph∆∞·ªõc Th·∫°nh', 'Ph∆∞·ªõc Vƒ©nh An', 'T√¢n An H·ªôi', 'T√¢n Ph√∫ Trung', 'T√¢n Th·∫°nh ƒê√¥ng', 'T√¢n Th·∫°nh T√¢y', 'T√¢n Th√¥ng H·ªôi', 'Th√°i M·ªπ', 'Trung An', 'Trung L·∫≠p H·∫°', 'Trung L·∫≠p Th∆∞·ª£ng', 'C·ªß Chi', 'Th·ªã tr·∫•n C·ªß Chi'],\n",
    "    'H√≥c M√¥n': ['B√† ƒêi·ªÉm', 'ƒê√¥ng Th·∫°nh', 'Nh·ªã B√¨nh', 'T√¢n Hi·ªáp', 'T√¢n Th·ªõi Nh√¨', 'T√¢n Xu√¢n', 'Th·ªõi Tam Th√¥n', 'Trung Ch√°nh', 'Xu√¢n Th·ªõi ƒê√¥ng', 'Xu√¢n Th·ªõi S∆°n', 'Xu√¢n Th·ªõi Th∆∞·ª£ng', 'H√≥c M√¥n', 'Th·ªã tr·∫•n H√≥c M√¥n'],\n",
    "    'B√¨nh Ch√°nh': ['An Ph√∫ T√¢y', 'B√¨nh Ch√°nh', 'B√¨nh H∆∞ng', 'B√¨nh L·ª£i', 'ƒêa Ph∆∞·ªõc', 'H∆∞ng Long', 'L√™ Minh Xu√¢n', 'Ph·∫°m VƒÉn Hai', 'Phong Ph√∫', 'Quy ƒê·ª©c', 'T√¢n Ki√™n', 'T√¢n Nh·ª±t', 'T√¢n Qu√Ω T√¢y', 'Vƒ©nh L·ªôc A', 'Vƒ©nh L·ªôc B', 'T√¢n T√∫c', 'Th·ªã tr·∫•n T√¢n T√∫c'],\n",
    "    'Nh√† B√®': ['Hi·ªáp Ph∆∞·ªõc', 'Long Th·ªõi', 'Nh∆°n ƒê·ª©c', 'Ph√∫ Xu√¢n', 'Ph∆∞·ªõc Ki·ªÉn', 'Ph∆∞·ªõc L·ªôc', 'Nh√† B√®', 'Th·ªã tr·∫•n Nh√† B√®'],\n",
    "    'C·∫ßn Gi·ªù': ['An Th·ªõi ƒê√¥ng', 'B√¨nh Kh√°nh', 'Long H√≤a', 'L√Ω Nh∆°n', 'Tam Th√¥n Hi·ªáp', 'Th·∫°nh An', 'C·∫ßn Th·∫°nh', 'Th·ªã tr·∫•n C·∫ßn Th·∫°nh']\n",
    "}\n",
    "\n",
    "# 2. MAPPING S√ÅP NH·∫¨P (QUAN TR·ªåNG: MAP M·ªöI V·ªÄ C≈®)\n",
    "# C·∫•u tr√∫c: ('Qu·∫≠n', 'T√™n M·ªõi'): 'T√™n C≈© ƒê·∫°i Di·ªán'\n",
    "merged_ward_mapping = {\n",
    "    # G√≤ V·∫•p: H·∫°nh Th√¥ng = P1 + P3 (Ch·ªçn P1)\n",
    "    ('G√≤ V·∫•p', 'H·∫°nh Th√¥ng'): '1',\n",
    "    ('G√≤ V·∫•p', 'Ph∆∞·ªùng H·∫°nh Th√¥ng'): '1',\n",
    "\n",
    "    # Qu·∫≠n 3: V√µ Th·ªã S√°u = P6 + P7 + P8 (Ch·ªçn P6)\n",
    "    ('Qu·∫≠n 3', 'V√µ Th·ªã S√°u'): '6',\n",
    "\n",
    "    # Qu·∫≠n 2 (Th·ªß ƒê·ª©c): An Kh√°nh m·ªõi = B√¨nh An + B√¨nh Kh√°nh (Ch·ªçn B√¨nh An)\n",
    "    ('Qu·∫≠n 2', 'An Kh√°nh'): 'B√¨nh An',\n",
    "    ('Th·ªß ƒê·ª©c', 'An Kh√°nh'): 'B√¨nh An',\n",
    "\n",
    "    # Qu·∫≠n 4: P12 nh·∫≠p v√†o P13\n",
    "    ('Qu·∫≠n 4', '12'): '13',\n",
    "\n",
    "    # Qu·∫≠n 5: P15 nh·∫≠p v√†o P12\n",
    "    ('Qu·∫≠n 5', '15'): '12',\n",
    "\n",
    "    # Qu·∫≠n 10: P3 nh·∫≠p v√†o P2\n",
    "    ('Qu·∫≠n 10', '3'): '2',\n",
    "\n",
    "    # Ph√∫ Nhu·∫≠n: P12 -> P11, P14 -> P13 (V√≠ d·ª•)\n",
    "    ('Ph√∫ Nhu·∫≠n', '12'): '11',\n",
    "    ('Ph√∫ Nhu·∫≠n', '14'): '13'\n",
    "}\n",
    "\n",
    "def normalize_district_key(district_raw):\n",
    "    if pd.isna(district_raw): return None\n",
    "    d = str(district_raw).strip()\n",
    "    if d in ['Q2', 'Q.2', 'Qu·∫≠n 2', 'District 2']: return 'Qu·∫≠n 2'\n",
    "    if d in ['Q9', 'Q.9', 'Qu·∫≠n 9', 'District 9']: return 'Qu·∫≠n 9'\n",
    "    if d in ['Th·ªß ƒê·ª©c', 'Q.Th·ªß ƒê·ª©c', 'TP Th·ªß ƒê·ª©c', 'Th√†nh ph·ªë Th·ªß ƒê·ª©c']: return 'Th·ªß ƒê·ª©c'\n",
    "    if d in hcm_wards_advanced: return d\n",
    "    if d.startswith('Q') and d[1:].isdigit(): return f\"Qu·∫≠n {d[1:]}\"\n",
    "    if d.startswith('Q.') and d[2:].isdigit(): return f\"Qu·∫≠n {d[2:]}\"\n",
    "    return d\n",
    "\n",
    "def extract_ward(row):\n",
    "    district_key = normalize_district_key(row['District'])\n",
    "    if not district_key: return None\n",
    "\n",
    "    # G·ªôp text ƒë·ªÉ t√¨m ki·∫øm\n",
    "    text_search = (str(row.get('Title', '')) + ' ' + str(row.get('Description', '')) + ' ' + str(row.get('Address', ''))).lower()\n",
    "\n",
    "    # --- ∆ØU TI√äN 1: CHECK MAPPING S√ÅP NH·∫¨P (T√äN M·ªöI) ---\n",
    "    for (dist, new_ward), old_ward_target in merged_ward_mapping.items():\n",
    "        # Ki·ªÉm tra ƒë√∫ng qu·∫≠n (ho·∫∑c qu·∫≠n thu·ªôc nh√≥m Th·ªß ƒê·ª©c)\n",
    "        is_match_district = (dist == district_key) or \\\n",
    "                            (district_key == 'Th·ªß ƒê·ª©c' and dist in ['Qu·∫≠n 2', 'Qu·∫≠n 9', 'Th·ªß ƒê·ª©c'])\n",
    "\n",
    "        if is_match_district:\n",
    "            # N·∫øu t√¨m th·∫•y t√™n ph∆∞·ªùng m·ªõi (VD: \"H·∫°nh Th√¥ng\") trong vƒÉn b·∫£n\n",
    "            if new_ward.lower() in text_search:\n",
    "                return old_ward_target # Tr·∫£ v·ªÅ t√™n c≈© (VD: \"1\")\n",
    "\n",
    "    # --- ∆ØU TI√äN 2: T√åM KI·∫æM B√åNH TH∆Ø·ªúNG ---\n",
    "    possible_wards = []\n",
    "    if district_key in hcm_wards_advanced:\n",
    "        possible_wards = hcm_wards_advanced[district_key]\n",
    "    elif district_key in ['Th√†nh ph·ªë Th·ªß ƒê·ª©c', 'TP. Th·ªß ƒê·ª©c']:\n",
    "         # N·∫øu input ch·ªâ ghi chung l√† TP Th·ªß ƒê·ª©c, ta t√¨m trong c·∫£ 3 qu·∫≠n c≈©\n",
    "         possible_wards = hcm_wards_advanced['Th·ªß ƒê·ª©c'] + hcm_wards_advanced['Qu·∫≠n 2'] + hcm_wards_advanced['Qu·∫≠n 9']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # T√¨m Ph∆∞·ªùng S·ªë (P1, F.1, Ph∆∞·ªùng 1...)\n",
    "    numeric_wards = [w for w in possible_wards if w.isdigit()]\n",
    "    for ward in numeric_wards:\n",
    "        # Regex th√¥ng minh: b·∫Øt p, f, ph∆∞·ªùng + s·ªë + kh√¥ng c√≥ s·ªë ƒë·∫±ng sau\n",
    "        pattern = r'(?:ph∆∞·ªùng|p|f)[\\.\\s]*0?' + ward + r'(?!\\d)'\n",
    "        if re.search(pattern, text_search):\n",
    "            return ward\n",
    "\n",
    "    # T√¨m Ph∆∞·ªùng Ch·ªØ (T√¢n ƒê·ªãnh, ƒêa Kao...)\n",
    "    named_wards = [w for w in possible_wards if not w.isdigit()]\n",
    "    named_wards.sort(key=len, reverse=True) # T√¨m t√™n d√†i tr∆∞·ªõc\n",
    "\n",
    "    for ward in named_wards:\n",
    "        if ward.lower() in text_search:\n",
    "            return ward\n",
    "\n",
    "    return None\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"ƒêang x·ª≠ l√Ω tr√≠ch xu·∫•t Ph∆∞·ªùng (Advanced Mapping)...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    df['Ward'] = df.apply(extract_ward, axis=1)\n",
    "\n",
    "    # Th·ªëng k√™\n",
    "    total = len(df)\n",
    "    found = df['Ward'].notna().sum()\n",
    "    print(f\"T·ªïng s·ªë d√≤ng: {total}\")\n",
    "    print(f\"T√¨m th·∫•y Ph∆∞·ªùng: {found} ({found/total*100:.2f}%)\")\n",
    "    print(\"-\" * 30)\n",
    "    print(df[['District', 'Ward']].head(10))\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(f\"ƒê√£ l∆∞u file k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói: {e}\")"
   ],
   "id": "581118ccf5bd6373",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω tr√≠ch xu·∫•t Ph∆∞·ªùng (Advanced Mapping)...\n",
      "T·ªïng s·ªë d√≤ng: 557\n",
      "T√¨m th·∫•y Ph∆∞·ªùng: 279 (50.09%)\n",
      "------------------------------\n",
      "       District             Ward\n",
      "0        Qu·∫≠n 8             None\n",
      "1       Qu·∫≠n 12    T√¢n Th·ªõi Hi·ªáp\n",
      "2        Qu·∫≠n 8               11\n",
      "3        Qu·∫≠n 9  TƒÉng Nh∆°n Ph√∫ A\n",
      "4        Qu·∫≠n 7          T√¢n Quy\n",
      "5  Huy·ªán Nh√† B√®             None\n",
      "6  Qu·∫≠n Th·ªß ƒê·ª©c             None\n",
      "7   Qu·∫≠n G√≤ V·∫•p             None\n",
      "8        Qu·∫≠n 7    T√¢n Thu·∫≠n T√¢y\n",
      "9  Qu·∫≠n Th·ªß ƒê·ª©c             None\n",
      "ƒê√£ l∆∞u file k·∫øt qu·∫£: ../../data/merge/Khang/Khangdone5.csv\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc ch·ªâ l·∫•y nh·ªØng c·ªôt c√≥ tr∆∞·ªùng Ward kh√¥ng null\n",
   "id": "5b29b3ff49811b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:20:58.833003600Z",
     "start_time": "2026-01-03T11:20:58.760404400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone5.csv'  # File v·ª´a ch·∫°y xong ·ªü b∆∞·ªõc tr∆∞·ªõc\n",
    "OUTPUT_FILE = '../../data/merge/Khang/Khangdone6.csv'  # File S·∫†CH S·∫º (Ch·ªâ ch·ª©a data c√≥ Ward)\n",
    "\n",
    "try:\n",
    "    print(f\"‚è≥ ƒêang ƒë·ªçc file '{INPUT_FILE}'...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    initial_count = len(df)\n",
    "\n",
    "    # 1. L·ªåC D·ªÆ LI·ªÜU\n",
    "    # Gi·ªØ l·∫°i c√°c d√≤ng m√† c·ªôt 'Ward' KH√îNG b·ªã r·ªóng (notna)\n",
    "    df_valid = df[df['Ward'].notna()]\n",
    "\n",
    "    # 2. L∆ØU FILE\n",
    "    df_valid.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # 3. B√ÅO C√ÅO K·∫æT QU·∫¢\n",
    "    valid_count = len(df_valid)\n",
    "    dropped_count = initial_count - valid_count\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚úÖ ƒê√É XU·∫§T TH√ÄNH C√îNG FILE: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"üìä T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: {initial_count}\")\n",
    "    print(f\"üü¢ S·ªë d√≤ng H·ª¢P L·ªÜ (C√≥ Ph∆∞·ªùng): {valid_count} d√≤ng\")\n",
    "    print(f\"üî¥ S·ªë d√≤ng B·ªä LO·∫†I (Null Ph∆∞·ªùng): {dropped_count} d√≤ng\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # In m·∫´u ƒë·ªÉ ki·ªÉm tra\n",
    "    print(\"\\nM·∫´u 5 d√≤ng d·ªØ li·ªáu chu·∫©n ƒë√£ l·ªçc:\")\n",
    "    print(df_valid[['District', 'Ward', 'Title']].head(5).to_string())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. B·∫°n h√£y ch·∫Øc ch·∫Øn ƒë√£ ch·∫°y code tr√≠ch xu·∫•t Ph∆∞·ªùng ·ªü b∆∞·ªõc tr∆∞·ªõc.\")\n",
    "except KeyError:\n",
    "    print(\"‚ùå L·ªói: File kh√¥ng c√≥ c·ªôt 'Ward'. H√£y ki·ªÉm tra l·∫°i.\")"
   ],
   "id": "39b0772b74dd1a16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc file '../../data/merge/Khang/Khangdone5.csv'...\n",
      "--------------------------------------------------\n",
      "‚úÖ ƒê√É XU·∫§T TH√ÄNH C√îNG FILE: ../../data/merge/Khang/Khangdone6.csv\n",
      "--------------------------------------------------\n",
      "üìä T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: 557\n",
      "üü¢ S·ªë d√≤ng H·ª¢P L·ªÜ (C√≥ Ph∆∞·ªùng): 279 d√≤ng\n",
      "üî¥ S·ªë d√≤ng B·ªä LO·∫†I (Null Ph∆∞·ªùng): 278 d√≤ng\n",
      "--------------------------------------------------\n",
      "\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu chu·∫©n ƒë√£ l·ªçc:\n",
      "  District             Ward                                                                                     Title\n",
      "1  Qu·∫≠n 12    T√¢n Th·ªõi Hi·ªáp                BaÃÅn nhaÃÄ mƒÉÃ£t ti√™ÃÄn 3 t√¢ÃÄng 6.6x28m giaÃÅ 16,99 tyÃâ ƒê∆∞∆°ÃÄng Tr∆∞∆°ng ThiÃ£ Hoa\n",
      "2   Qu·∫≠n 8               11                                     Nh√† M·∫∑t ti·ªÅn ƒë∆∞·ªùng Phong Ph√∫ - P11, Gi√° : 5,6 T·ªâ (TL)\n",
      "3   Qu·∫≠n 9  TƒÉng Nh∆°n Ph√∫ A       TRUNG T√ÇM QU·∫¨N 9 ‚Äì SI√äU PH·∫®M M·∫∂T TI·ªÄN L√É XU√ÇN OAI ‚Äì 198M¬≤ ‚Äì 2 T·∫¶NG BTCT ‚Äì GI√Å 24 T·ª∂\n",
      "4   Qu·∫≠n 7          T√¢n Quy        SANG G·∫§P NH√Ä MT ƒê∆Ø·ªúNG S·ªê - NGANG 4M - 3 T·∫¶NG - P. T√ÇN QUY, Q7 - NH·ªàNH 12 T·ª∂ ( TL )\n",
      "8   Qu·∫≠n 7    T√¢n Thu·∫≠n T√¢y  üè† B√ÅN NH√Ä M·∫∂T TI·ªÄN HU·ª≤NH T·∫§N PH√ÅT, CH·ªà 200M ƒê·∫æN QU·∫¨N 4 ‚Äì V·ªä TR√ç ƒê·∫ÆC ƒê·ªäA, GI√Å CH·ªà 13 T·ª∂ üè†\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc ra c√°c tr∆∞·ªùng c·∫ßn thi·∫øt",
   "id": "d67df8152ad19b53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:21:27.183Z",
     "start_time": "2026-01-03T11:21:27.122738200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Khang/Khangdone6.csv'  # File ƒë√£ c√≥ ƒë·ªß Ph∆∞·ªùng\n",
    "OUTPUT_FILE = '../../data/merge/Khang_done.csv'  # File k·∫øt qu·∫£\n",
    "\n",
    "try:\n",
    "    print(f\"‚è≥ ƒêang ƒë·ªçc file '{INPUT_FILE}'...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # 1. X·ª¨ L√ù C·ªòT \"IS HEM\" (T·∫°o t·ª´ Is_MatTien)\n",
    "    # Logic: N·∫øu Is_MatTien = 0 th√¨ Is Hem = 1\n",
    "    if 'Is Hem' not in df.columns:\n",
    "        print(\"- ƒêang t·∫°o c·ªôt 'Is Hem'...\")\n",
    "        df['Is Hem'] = df['Is_MatTien'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    # 2. X·ª¨ L√ù C·ªòT \"POST TIME\"\n",
    "    # Trong code c≈© t√™n l√† 'Post_Time' (c√≥ g·∫°ch d∆∞·ªõi), n·∫øu b·∫°n mu·ªën t√™n l√† 'Post Time' (c√≥ d·∫•u c√°ch) th√¨ ƒë·ªïi l·∫°i\n",
    "    if 'Post_Time' in df.columns:\n",
    "        df.rename(columns={'Post_Time': 'Post Time'}, inplace=True)\n",
    "\n",
    "    # 3. DANH S√ÅCH 12 C·ªòT B·∫†N Y√äU C·∫¶U\n",
    "    target_cols = [\n",
    "        'Price_Billion',\n",
    "        'Price_Per_m2',\n",
    "        'Area_m2',\n",
    "        'District',\n",
    "        'Ward',\n",
    "        'Bedrooms',\n",
    "        'Is_MatTien',\n",
    "        'Width_m',\n",
    "        'Floors',\n",
    "        'Is Hem',\n",
    "        'Post Time',\n",
    "        'Toilets'\n",
    "    ]\n",
    "\n",
    "    # 4. TH·ª∞C HI·ªÜN L·ªåC V√Ä L∆ØU FILE\n",
    "    # Ch·ªâ l·∫•y ƒë√∫ng c√°c c·ªôt trong danh s√°ch\n",
    "    df_final = df[target_cols]\n",
    "\n",
    "    df_final.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚úÖ ƒê√É XONG! File ch·ªâ ch·ª©a ƒë√∫ng 12 c·ªôt: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(df_final.head().to_string())\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt {e} trong file g·ªëc. H√£y ki·ªÉm tra l·∫°i t√™n c·ªôt.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói: {e}\")"
   ],
   "id": "c2ff62bdc74e2bec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc file '../../data/merge/Khang/Khangdone6.csv'...\n",
      "- ƒêang t·∫°o c·ªôt 'Is Hem'...\n",
      "--------------------------------------------------\n",
      "‚úÖ ƒê√É XONG! File ch·ªâ ch·ª©a ƒë√∫ng 12 c·ªôt: ../../data/merge/Khang_done.csv\n",
      "--------------------------------------------------\n",
      "   Price_Billion  Price_Per_m2  Area_m2 District             Ward  Bedrooms  Is_MatTien  Width_m  Floors  Is Hem   Post Time  Toilets\n",
      "0          16.99        212.38     80.0  Qu·∫≠n 12    T√¢n Th·ªõi Hi·ªáp         5           0     5.00     3.5       1  18/11/2025        5\n",
      "1           5.60        127.27     44.0   Qu·∫≠n 8               11         2           1     2.90     2.0       0  16/12/2025        3\n",
      "2          24.00        121.21    198.0   Qu·∫≠n 9  TƒÉng Nh∆°n Ph√∫ A         4           1     7.48     2.0       0  04/12/2025        4\n",
      "3          12.00        150.00     80.0   Qu·∫≠n 7          T√¢n Quy         2           1     4.00     3.0       0  18/11/2025        3\n",
      "4          11.10        179.03     62.0   Qu·∫≠n 7    T√¢n Thu·∫≠n T√¢y         2           1     5.34     1.0       0  21/11/2025        0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:21:35.788443800Z",
     "start_time": "2026-01-03T11:21:35.720130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def inspect_csv(df):\n",
    "    print(\"===== CSV OVERVIEW =====\")\n",
    "    print(f\"Rows    : {df.shape[0]}\")\n",
    "    print(f\"Columns : {df.shape[1]}\")\n",
    "    print(\"\\n--- Data types ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Memory usage ---\")\n",
    "    print(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2), \"MB\")\n",
    "\n",
    "\n",
    "df_raw = pd.read_csv(\"../../data/merge/Khang_done.csv\")\n",
    "inspect_csv(df_raw)\n"
   ],
   "id": "8182ee9957157e3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CSV OVERVIEW =====\n",
      "Rows    : 279\n",
      "Columns : 12\n",
      "\n",
      "--- Data types ---\n",
      "Price_Billion    float64\n",
      "Price_Per_m2     float64\n",
      "Area_m2          float64\n",
      "District          object\n",
      "Ward              object\n",
      "Bedrooms           int64\n",
      "Is_MatTien         int64\n",
      "Width_m          float64\n",
      "Floors           float64\n",
      "Is Hem             int64\n",
      "Post Time         object\n",
      "Toilets            int64\n",
      "dtype: object\n",
      "\n",
      "--- Memory usage ---\n",
      "0.07 MB\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:21:43.084697800Z",
     "start_time": "2026-01-03T11:21:42.982633600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def report_missing_values(df):\n",
    "    print(\"===== MISSING VALUE REPORT =====\")\n",
    "    missing = df.isna().sum()\n",
    "    percent = (missing / len(df)) * 100\n",
    "    report = pd.DataFrame({\n",
    "        \"Missing_Count\": missing,\n",
    "        \"Percent_Missing (%)\": percent.round(2)\n",
    "    }).sort_values(by=\"Missing_Count\", ascending=False)\n",
    "    print(report)\n",
    "    return report\n",
    "\n",
    "\n",
    "report_missing_values(df_raw)"
   ],
   "id": "b68e9d33b916e891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MISSING VALUE REPORT =====\n",
      "               Missing_Count  Percent_Missing (%)\n",
      "Price_Billion              0                  0.0\n",
      "Price_Per_m2               0                  0.0\n",
      "Area_m2                    0                  0.0\n",
      "District                   0                  0.0\n",
      "Ward                       0                  0.0\n",
      "Bedrooms                   0                  0.0\n",
      "Is_MatTien                 0                  0.0\n",
      "Width_m                    0                  0.0\n",
      "Floors                     0                  0.0\n",
      "Is Hem                     0                  0.0\n",
      "Post Time                  0                  0.0\n",
      "Toilets                    0                  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               Missing_Count  Percent_Missing (%)\n",
       "Price_Billion              0                  0.0\n",
       "Price_Per_m2               0                  0.0\n",
       "Area_m2                    0                  0.0\n",
       "District                   0                  0.0\n",
       "Ward                       0                  0.0\n",
       "Bedrooms                   0                  0.0\n",
       "Is_MatTien                 0                  0.0\n",
       "Width_m                    0                  0.0\n",
       "Floors                     0                  0.0\n",
       "Is Hem                     0                  0.0\n",
       "Post Time                  0                  0.0\n",
       "Toilets                    0                  0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Percent_Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price_Billion</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Per_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is_MatTien</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width_m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floors</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is Hem</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toilets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
