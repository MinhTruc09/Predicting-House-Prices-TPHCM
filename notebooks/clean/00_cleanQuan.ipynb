{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ki·ªÉm tra t·ªïng th·ªÉ tr∆∞·ªùng v√† s·ªë l∆∞·ª£ng data",
   "id": "ac30fe2942a2ab71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:31:14.929294700Z",
     "start_time": "2026-01-05T15:31:14.752258500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def inspect_csv(df):\n",
    "    print(\"===== CSV OVERVIEW =====\")\n",
    "    print(f\"Rows    : {df.shape[0]}\")\n",
    "    print(f\"Columns : {df.shape[1]}\")\n",
    "    print(\"\\n--- Data types ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Memory usage ---\")\n",
    "    print(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2), \"MB\")\n",
    "\n",
    "\n",
    "df_raw = pd.read_csv(\"../../data/merge/Quanthieufix.csv\")\n",
    "inspect_csv(df_raw)\n"
   ],
   "id": "20c298e53714000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CSV OVERVIEW =====\n",
      "Rows    : 3424\n",
      "Columns : 22\n",
      "\n",
      "--- Data types ---\n",
      "id                    int64\n",
      "Page                  int64\n",
      "Title                object\n",
      "Price_Raw            object\n",
      "Price_Billion       float64\n",
      "Price_per_m2         object\n",
      "Area_m2              object\n",
      "District             object\n",
      "Address              object\n",
      "Bedrooms            float64\n",
      "Toilets             float64\n",
      "Post_Time            object\n",
      "Link                 object\n",
      "Description          object\n",
      "M·ª©c ƒë·ªô giao d·ªãch     object\n",
      "M·∫∑t ti·ªÅn             object\n",
      "Chi·ªÅu s√¢u            object\n",
      "∆Øu ƒëi·ªÉm BƒêS          object\n",
      "N·ªôi th·∫•t             object\n",
      "S·ªë ban c√¥ng         float64\n",
      "H∆∞·ªõng ban c√¥ng       object\n",
      "Ti·ªán √≠ch             object\n",
      "dtype: object\n",
      "\n",
      "--- Memory usage ---\n",
      "6.63 MB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "H√†m ki·ªÉm tra v√† th√¥ng b√°o √¥ thi·∫øu d·ªØ li·ªáu theo tung c·ªôt",
   "id": "2c1f9cbe35625d22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:31:23.174275800Z",
     "start_time": "2026-01-05T15:31:23.155740400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def report_missing_values(df):\n",
    "    print(\"===== MISSING VALUE REPORT =====\")\n",
    "    missing = df.isna().sum()\n",
    "    percent = (missing / len(df)) * 100\n",
    "    report = pd.DataFrame({\n",
    "        \"Missing_Count\": missing,\n",
    "        \"Percent_Missing (%)\": percent.round(2)\n",
    "    }).sort_values(by=\"Missing_Count\", ascending=False)\n",
    "    print(report)\n",
    "    return report\n"
   ],
   "id": "d0407ac1463bd159",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:31:25.124835500Z",
     "start_time": "2026-01-05T15:31:24.975522800Z"
    }
   },
   "cell_type": "code",
   "source": "report_missing_values(df_raw)",
   "id": "36937fdb1bf82be9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MISSING VALUE REPORT =====\n",
      "                  Missing_Count  Percent_Missing (%)\n",
      "N·ªôi th·∫•t                   3419                99.85\n",
      "S·ªë ban c√¥ng                3417                99.80\n",
      "H∆∞·ªõng ban c√¥ng             3338                97.49\n",
      "Ti·ªán √≠ch                   3330                97.25\n",
      "Chi·ªÅu s√¢u                  3248                94.86\n",
      "M·ª©c ƒë·ªô giao d·ªãch           3205                93.60\n",
      "∆Øu ƒëi·ªÉm BƒêS                2257                65.92\n",
      "Toilets                    2164                63.20\n",
      "Bedrooms                   2074                60.57\n",
      "M·∫∑t ti·ªÅn                   1956                57.13\n",
      "Price_Raw                   959                28.01\n",
      "Price_Billion               959                28.01\n",
      "Price_per_m2                919                26.84\n",
      "District                    744                21.73\n",
      "Post_Time                   731                21.35\n",
      "Description                 731                21.35\n",
      "Area_m2                     731                21.35\n",
      "Address                      64                 1.87\n",
      "Title                         1                 0.03\n",
      "Page                          0                 0.00\n",
      "id                            0                 0.00\n",
      "Link                          0                 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  Missing_Count  Percent_Missing (%)\n",
       "N·ªôi th·∫•t                   3419                99.85\n",
       "S·ªë ban c√¥ng                3417                99.80\n",
       "H∆∞·ªõng ban c√¥ng             3338                97.49\n",
       "Ti·ªán √≠ch                   3330                97.25\n",
       "Chi·ªÅu s√¢u                  3248                94.86\n",
       "M·ª©c ƒë·ªô giao d·ªãch           3205                93.60\n",
       "∆Øu ƒëi·ªÉm BƒêS                2257                65.92\n",
       "Toilets                    2164                63.20\n",
       "Bedrooms                   2074                60.57\n",
       "M·∫∑t ti·ªÅn                   1956                57.13\n",
       "Price_Raw                   959                28.01\n",
       "Price_Billion               959                28.01\n",
       "Price_per_m2                919                26.84\n",
       "District                    744                21.73\n",
       "Post_Time                   731                21.35\n",
       "Description                 731                21.35\n",
       "Area_m2                     731                21.35\n",
       "Address                      64                 1.87\n",
       "Title                         1                 0.03\n",
       "Page                          0                 0.00\n",
       "id                            0                 0.00\n",
       "Link                          0                 0.00"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Percent_Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N·ªôi th·∫•t</th>\n",
       "      <td>3419</td>\n",
       "      <td>99.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S·ªë ban c√¥ng</th>\n",
       "      <td>3417</td>\n",
       "      <td>99.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H∆∞·ªõng ban c√¥ng</th>\n",
       "      <td>3338</td>\n",
       "      <td>97.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ti·ªán √≠ch</th>\n",
       "      <td>3330</td>\n",
       "      <td>97.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chi·ªÅu s√¢u</th>\n",
       "      <td>3248</td>\n",
       "      <td>94.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M·ª©c ƒë·ªô giao d·ªãch</th>\n",
       "      <td>3205</td>\n",
       "      <td>93.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>∆Øu ƒëi·ªÉm BƒêS</th>\n",
       "      <td>2257</td>\n",
       "      <td>65.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toilets</th>\n",
       "      <td>2164</td>\n",
       "      <td>63.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>2074</td>\n",
       "      <td>60.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M·∫∑t ti·ªÅn</th>\n",
       "      <td>1956</td>\n",
       "      <td>57.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Raw</th>\n",
       "      <td>959</td>\n",
       "      <td>28.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Billion</th>\n",
       "      <td>959</td>\n",
       "      <td>28.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_per_m2</th>\n",
       "      <td>919</td>\n",
       "      <td>26.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <td>744</td>\n",
       "      <td>21.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post_Time</th>\n",
       "      <td>731</td>\n",
       "      <td>21.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>731</td>\n",
       "      <td>21.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_m2</th>\n",
       "      <td>731</td>\n",
       "      <td>21.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Address</th>\n",
       "      <td>64</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Page</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Link</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:31:38.049338400Z",
     "start_time": "2026-01-05T15:31:37.989021500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask = df_raw['Post_Time'].isna()\n",
    "\n",
    "mask.sum(), len(df_raw)\n"
   ],
   "id": "bdcfb08f46f99f41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(731), 3424)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:28.352317500Z",
     "start_time": "2026-01-03T11:17:28.273500300Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].dtype\n",
   "id": "adc71e7d648fe738",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:29.553356600Z",
     "start_time": "2026-01-03T11:17:29.487719500Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].value_counts().head(10)\n",
   "id": "158bfcf219c5b884",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Post_Time\n",
       "27/08/2025    54\n",
       "01/09/2025    45\n",
       "02/09/2025    42\n",
       "10/09/2025    23\n",
       "28/08/2025    22\n",
       "15/12/2025    22\n",
       "11/09/2025    20\n",
       "03/09/2025    20\n",
       "25/08/2025    20\n",
       "23/08/2025    17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parse post time ra datatype datetime",
   "id": "8a507ade70500813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:32.093506600Z",
     "start_time": "2026-01-03T11:17:32.063333100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_raw['Post_Time'] = pd.to_datetime(\n",
    "    df_raw['Post_Time'],\n",
    "    format='%d/%m/%Y',\n",
    "    errors='coerce'\n",
    ")\n"
   ],
   "id": "aca7fbb23a407919",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:33.843068900Z",
     "start_time": "2026-01-03T11:17:33.798248500Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].dtype\n",
   "id": "f5ef27c5c3473e10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T11:17:35.103142700Z",
     "start_time": "2026-01-03T11:17:35.023460Z"
    }
   },
   "cell_type": "code",
   "source": "df_raw['Post_Time'].isna().sum(), len(df_raw)\n",
   "id": "3a3fd6a6430db6ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), 778)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f92435d7857f9ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:31:51.696398300Z",
     "start_time": "2026-01-05T15:31:51.192741900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- C·∫§U H√åNH T√äN FILE ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieufix.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone.csv'\n",
    "\n",
    "# --- H√ÄM X·ª¨ L√ù ---\n",
    "def extract_width(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "\n",
    "    # Chu·∫©n h√≥a\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    # M·∫™U 1: \"chi·ªÅu r·ªông 7.7m\"\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50:\n",
    "                val = val / 10\n",
    "            if 0 < val < 50:\n",
    "                return val\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # M·∫™U 2: \"ngang 5m\"\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50:\n",
    "                return val\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # M·∫™U 3: D·∫°ng AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        temp_width = None\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2)\n",
    "\n",
    "                if 'm' in m.group(0) and 2 <= width < 50:\n",
    "                    return width\n",
    "                if 2 <= width < 50:\n",
    "                    temp_width = width\n",
    "            except:\n",
    "                continue\n",
    "        if temp_width is not None:\n",
    "            return temp_width\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_mattien(row):\n",
    "    text = str(row.get('Title', '')) + \" \" + str(row.get('Description', ''))\n",
    "    text = text.lower()\n",
    "\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text:\n",
    "            return 0\n",
    "\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text:\n",
    "            return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"‚è≥ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "\n",
    "try:\n",
    "    # 1. ƒê·ªçc file\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # 2. √âP KI·ªÇU S·ªê (C·ª∞C K·ª≤ QUAN TR·ªåNG ‚Äì FIX L·ªñI C·ª¶A M√ÄY)\n",
    "    df['Area_m2'] = pd.to_numeric(df['Area_m2'], errors='coerce')\n",
    "    df['Price_Billion'] = pd.to_numeric(df['Price_Billion'], errors='coerce')\n",
    "\n",
    "    # 3. X·ª≠ l√Ω chi·ªÅu ngang\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # 4. X·ª≠ l√Ω m·∫∑t ti·ªÅn\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # 5. T√çNH ƒê∆†N GI√Å ‚Äì KH√îNG D√ôNG APPLY\n",
    "    df['Price_Per_m2'] = (df['Price_Billion'] * 1000) / df['Area_m2']\n",
    "    df['Price_Per_m2'] = df['Price_Per_m2'].round(2)\n",
    "    df['Price_Per_m2'] = df['Price_Per_m2'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 6. L∆∞u file\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"‚úÖ XONG! File k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(df[['Title', 'Width_m', 'Is_MatTien', 'Price_Per_m2']].head().to_string())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå L·ªói kh√°c:\", e)\n"
   ],
   "id": "d9741413d20427be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "‚úÖ XONG! File k·∫øt qu·∫£: ../../data/merge/Quanthieudone.csv\n",
      "----------------------------------------\n",
      "                                                                                     Title  Width_m  Is_MatTien  Price_Per_m2\n",
      "0  C·∫ßn ti·ªÅn b√°n g·∫•p nh√† ri√™ng gi√° si√™u h·ªùi t·∫°i Vƒ©nh Kh√°nh, Ph∆∞·ªùng 8, Qu·∫≠n 4, 3,99 t·ª∑, 45m2      4.5           1         88.67\n",
      "1                        Si√™u ph·∫©m nh√† 35m¬≤ ngay tr·ª•c ƒë∆∞·ªùng Ng√¥ Gia T·ª±, Qu·∫≠n 4, gi√° 1,8 t·ª∑      4.0           1         50.00\n",
      "2                                          Ch·ªß ƒëi M·ªπ ƒë·ªãnh c∆∞ c·∫ßn b√°n nh√† ƒë∆∞·ªùng ƒêo√†n VƒÉn B∆°      4.0           1         70.00\n",
      "3     BaÃÅn nhaÃÄ h·∫ªm xe h∆°i T√¥n Th√¢ÃÅt Thuy√™ÃÅt, Ph∆∞∆°ÃÄng 16, Qu·∫≠n 4, 277m2, 2 t√¢ÃÄng, giaÃÅ reÃâ      9.0           0         79.42\n",
      "4                 Nh√† 2 t·∫•m ƒë·∫πp nh∆∞ m∆°, h·∫ªm xe h∆°i 3m, Qu·∫≠n 4, gi√° h·ªùi cho ng∆∞·ªùi nhanh tay      3.0           0        171.17\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Xu·∫•t data m√† 1 trong c√°c tr∆∞·ªùng Toilets,Bedrooms,  Price_Billion,Price_Per_m2 ,Area_m2  b·ªã thi·∫øu",
   "id": "3a9784a7825b5dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:32:03.562040Z",
     "start_time": "2026-01-05T15:32:03.476966300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone.csv'  # File d·ªØ li·ªáu s·∫°ch t·ª´ b∆∞·ªõc tr∆∞·ªõc\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone1.csv'  # File ch·ª©a c√°c d√≤ng b·ªã l·ªói\n",
    "\n",
    "try:\n",
    "    print(f\"ƒêang ƒë·ªçc file {INPUT_FILE}...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # Danh s√°ch c√°c c·ªôt c·∫ßn ki·ªÉm tra\n",
    "    check_cols = ['Address']\n",
    "\n",
    "    # L·ªçc c√°c d√≤ng c√≥ √≠t nh·∫•t 1 √¥ b·ªã Null trong danh s√°ch c·ªôt tr√™n\n",
    "    # how='any' nghƒ©a l√† ch·ªâ c·∫ßn 1 c·ªôt b·ªã thi·∫øu l√† l·∫•y ra\n",
    "    df_missing = df[df[check_cols].isnull().any(axis=1)]\n",
    "\n",
    "    # L∆∞u ra file m·ªõi\n",
    "    df_missing.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"X·ª¨ L√ù XONG!\")\n",
    "    print(f\"T·ªïng s·ªë d√≤ng b·ªã thi·∫øu th√¥ng tin: {len(df_missing)} d√≤ng\")\n",
    "    print(f\"ƒê√£ xu·∫•t d·ªØ li·ªáu ra file: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # In th·ªëng k√™ chi ti·∫øt l·∫°i m·ªôt l·∫ßn n·ªØa cho t·∫≠p d·ªØ li·ªáu n√†y\n",
    "    print(\"Chi ti·∫øt s·ªë l∆∞·ª£ng thi·∫øu trong file n√†y:\")\n",
    "    print(df_missing[check_cols].isnull().sum())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y code t·∫°o file data_clean_final.csv ·ªü b∆∞·ªõc tr∆∞·ªõc.\")\n",
    "except KeyError as e:\n",
    "    print(f\"L·ªói: File thi·∫øu c·ªôt {e}. H√£y ki·ªÉm tra l·∫°i t√™n c·ªôt trong file CSV.\")"
   ],
   "id": "d6ca4e69ab1db025",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang ƒë·ªçc file ../../data/merge/Quanthieudone.csv...\n",
      "----------------------------------------\n",
      "X·ª¨ L√ù XONG!\n",
      "T·ªïng s·ªë d√≤ng b·ªã thi·∫øu th√¥ng tin: 64 d√≤ng\n",
      "ƒê√£ xu·∫•t d·ªØ li·ªáu ra file: ../../data/merge/Quanthieudone1.csv\n",
      "----------------------------------------\n",
      "Chi ti·∫øt s·ªë l∆∞·ª£ng thi·∫øu trong file n√†y:\n",
      "Address    64\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "D·ª±a k·∫øt qu·∫£ l·ªçc width t√¨m l·∫°i tr∆∞·ªùng Area_m2 b·ªã tr·ªëng, t√≠nh l·∫°i s·ªë ti·ªÅn tr√™n m·ªói m2",
   "id": "dcd412c2e389cdfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:32:12.345359800Z",
     "start_time": "2026-01-05T15:32:11.830471300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone2.csv'\n",
    "\n",
    "# ================= 1. GI·ªÆ NGUY√äN H√ÄM C·ª¶A B·∫†N (ƒê√£ t·ªëi ∆∞u) =================\n",
    "def extract_width(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    # M·∫™U 1: Chi·ªÅu r·ªông...\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50: val = val / 10\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 2: Ngang...\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 3: AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2)\n",
    "                if 'm' in m.group(0) and 2 <= width < 50: return width\n",
    "                if 2 <= width < 50: temp_width = width\n",
    "            except: continue\n",
    "        if 'temp_width' in locals(): return temp_width\n",
    "    return None\n",
    "\n",
    "def check_mattien(row):\n",
    "    text = str(row['Title']) + \" \" + str(row['Description'])\n",
    "    text = text.lower()\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text: return 0\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text: return 1\n",
    "    return 0\n",
    "\n",
    "# ================= 2. H√ÄM M·ªöI: T√åM CHI·ªÄU D√ÄI & T√çNH DI·ªÜN T√çCH =================\n",
    "def recover_missing_area(row):\n",
    "    # N·∫øu Di·ªán t√≠ch ƒë√£ c√≥ d·ªØ li·ªáu h·ª£p l·ªá (>0) th√¨ gi·ªØ nguy√™n, kh√¥ng c·∫ßn t√≠nh l·∫°i\n",
    "    current_area = row.get('Area_m2', 0)\n",
    "    if pd.notnull(current_area) and current_area > 0:\n",
    "        return current_area\n",
    "\n",
    "    # N·∫øu kh√¥ng c√≥ Chi·ªÅu Ngang (Width), th√¨ ch·ªãu thua, kh√¥ng t√≠nh ƒë∆∞·ª£c Area\n",
    "    width = row.get('Width_m')\n",
    "    if pd.isnull(width) or width == 0:\n",
    "        return current_area # Tr·∫£ v·ªÅ nh∆∞ c≈© (Null ho·∫∑c 0)\n",
    "\n",
    "    # --- B·∫ÆT ƒê·∫¶U ƒêI T√åM CHI·ªÄU D√ÄI (LENGTH) ---\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    length = None\n",
    "\n",
    "    # M·∫™U A: T√¨m t·ª´ kh√≥a \"D√†i...\" (V√≠ d·ª•: Ngang 5 d√†i 20)\n",
    "    match_dai = re.search(r'd√†i\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match_dai:\n",
    "        try:\n",
    "            val = float(match_dai.group(1))\n",
    "            # Chi·ªÅu d√†i th∆∞·ªùng ph·∫£i l·ªõn h∆°n chi·ªÅu r·ªông v√† < 100m (nh√† ph·ªë)\n",
    "            if val >= width and val < 150:\n",
    "                length = val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U B: T√¨m trong c·ª•m AxB (V√≠ d·ª•: 5x20)\n",
    "    # Logic: N·∫øu Width kh·ªõp v·ªõi 1 trong 2 s·ªë, th√¨ s·ªë kia l√† Length\n",
    "    if length is None:\n",
    "        matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                # N·∫øu 1 trong 2 s·ªë x·∫•p x·ªâ b·∫±ng Width m√† m√¨nh ƒë√£ t√¨m ra\n",
    "                # (Cho sai s·ªë 0.1 ph√≤ng tr∆∞·ªùng h·ª£p l√†m tr√≤n)\n",
    "                if abs(n1 - width) < 0.1: length = n2\n",
    "                elif abs(n2 - width) < 0.1: length = n1\n",
    "\n",
    "                if length: break\n",
    "            except: continue\n",
    "\n",
    "    # --- T√çNH TO√ÅN DI·ªÜN T√çCH ---\n",
    "    if length and length > 0:\n",
    "        calculated_area = width * length\n",
    "        return round(calculated_area, 2)\n",
    "\n",
    "    return current_area # Kh√¥ng t√¨m th·∫•y Length th√¨ tr·∫£ v·ªÅ Null nh∆∞ c≈©\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t Width (nh∆∞ c≈©)\n",
    "    print(\"- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang...\")\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 2: C·ª®U D·ªÆ LI·ªÜU AREA (B∆∞·ªõc m·ªõi)\n",
    "    # L·∫•p ƒë·∫ßy c√°c √¥ Area b·ªã tr·ªëng b·∫±ng c√°ch t√≠nh Width * Length\n",
    "    print(\"- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\")\n",
    "    df['Area_m2'] = df.apply(recover_missing_area, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·∫∑t ti·ªÅn\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 4: T√≠nh l·∫°i ƒë∆°n gi√° (Sau khi ƒë√£ c·ª©u ƒë∆∞·ª£c Area)\n",
    "    df['Price_Per_m2'] = df.apply(\n",
    "        lambda x: round((x['Price_Billion'] * 1000) / x['Area_m2'], 2)\n",
    "        if pd.notnull(x['Area_m2']) and x['Area_m2'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Xong! File k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # In ki·ªÉm tra nh·ªØng d√≤ng m√† Area ƒë∆∞·ª£c c·ª©u s·ªëng (tr∆∞·ªõc ƒë√≥ l√† null/0 nh∆∞ng gi·ªù c√≥ Width*Length)\n",
    "    # Logic in: C√≥ Width, C√≥ Area, nh∆∞ng Price_Raw c√≥ th·ªÉ check sau\n",
    "    print(\"M·∫´u 5 d√≤ng d·ªØ li·ªáu sau khi t√≠nh to√°n:\")\n",
    "    print(df[['id', 'Width_m', 'Area_m2', 'Price_Per_m2']].head(10).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói: {e}\")"
   ],
   "id": "c72405e0e2fda10a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang...\n",
      "- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\n",
      "Xong! File k·∫øt qu·∫£: ../../data/merge/Quanthieudone2.csv\n",
      "------------------------------\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu sau khi t√≠nh to√°n:\n",
      "          id  Width_m  Area_m2  Price_Per_m2\n",
      "0  305927397      4.5     45.0         88.67\n",
      "1  306304969      4.0     36.0         50.00\n",
      "2  306316580      4.0     45.0         70.00\n",
      "3  105658348      9.0    277.0         79.42\n",
      "4  306031048      3.0     22.2        171.17\n",
      "5  305996311      3.0     20.0        250.00\n",
      "6  306060382     20.0     84.0         35.71\n",
      "7  305998797      NaN     36.6        100.82\n",
      "8  304760587      6.1     60.3        152.57\n",
      "9  306005353      5.0     40.0        207.50\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tr√≠ch xu·∫•t b·ªï sung th√™m t∆∞·ªùng Floors c·∫£i ti·∫øn code tr√™n",
   "id": "421a6a0ca11cd12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:32:18.668485900Z",
     "start_time": "2026-01-05T15:32:17.994864300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# H√£y ƒë·∫£m b·∫£o t√™n file INPUT ƒë√∫ng v·ªõi file b·∫°n ƒëang c√≥\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone2.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone3.csv'\n",
    "\n",
    "# ================= 1. H√ÄM TR√çCH XU·∫§T CHI·ªÄU NGANG (WIDTH) =================\n",
    "def extract_width(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    # M·∫™U 1: Chi·ªÅu r·ªông...\n",
    "    match = re.search(r'chi·ªÅu\\s*r·ªông\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if val > 50: val = val / 10\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 2: Ngang...\n",
    "    match = re.search(r'(?:ngang|r·ªông|mt)(?:.{0,15}?)\\s+(\\d+[.]?\\d*)', text)\n",
    "    if match:\n",
    "        try:\n",
    "            val = float(match.group(1))\n",
    "            if 0 < val < 50: return val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U 3: AxB\n",
    "    matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                width = min(n1, n2)\n",
    "                if 'm' in m.group(0) and 2 <= width < 50: return width\n",
    "                if 2 <= width < 50: temp_width = width\n",
    "            except: continue\n",
    "        if 'temp_width' in locals(): return temp_width\n",
    "    return None\n",
    "\n",
    "# ================= 2. H√ÄM X√ÅC ƒê·ªäNH M·∫∂T TI·ªÄN =================\n",
    "def check_mattien(row):\n",
    "    text = str(row['Title']) + \" \" + str(row['Description'])\n",
    "    text = text.lower()\n",
    "    exclude_keywords = ['s√°t m·∫∑t ti·ªÅn', 'c√°ch m·∫∑t ti·ªÅn', 'g·∫ßn m·∫∑t ti·ªÅn', 'sau m·∫∑t ti·ªÅn']\n",
    "    for kw in exclude_keywords:\n",
    "        if kw in text: return 0\n",
    "    positive_keywords = ['m·∫∑t ti·ªÅn', 'mtkd', 'mt ƒë∆∞·ªùng', 'l√¥ g√≥c', '2 m·∫∑t ti·ªÅn']\n",
    "    for kw in positive_keywords:\n",
    "        if kw in text: return 1\n",
    "    return 0\n",
    "\n",
    "# ================= 3. H√ÄM T√çNH TO√ÅN L·∫†I DI·ªÜN T√çCH =================\n",
    "def recover_missing_area(row):\n",
    "    current_area = row.get('Area_m2', 0)\n",
    "    if pd.notnull(current_area) and current_area > 0:\n",
    "        return current_area\n",
    "\n",
    "    width = row.get('Width_m')\n",
    "    if pd.isnull(width) or width == 0:\n",
    "        return current_area\n",
    "\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace(',', '.')\n",
    "    text = re.sub(r'[‚ùå*√ó]', 'x', text)\n",
    "    text = re.sub(r'[‚Äì\\-_:]', ' ', text)\n",
    "\n",
    "    length = None\n",
    "    # M·∫™U A: T√¨m t·ª´ kh√≥a \"D√†i...\"\n",
    "    match_dai = re.search(r'd√†i\\s*(\\d+[.]?\\d*)', text)\n",
    "    if match_dai:\n",
    "        try:\n",
    "            val = float(match_dai.group(1))\n",
    "            if val >= width and val < 150:\n",
    "                length = val\n",
    "        except: pass\n",
    "\n",
    "    # M·∫™U B: T√¨m trong c·ª•m AxB\n",
    "    if length is None:\n",
    "        matches = list(re.finditer(r'(\\d+[.]?\\d*)\\s*m?\\s*x\\s*(\\d+[.]?\\d*)', text))\n",
    "        for m in matches:\n",
    "            try:\n",
    "                n1 = float(m.group(1))\n",
    "                n2 = float(m.group(2))\n",
    "                if abs(n1 - width) < 0.1: length = n2\n",
    "                elif abs(n2 - width) < 0.1: length = n1\n",
    "                if length: break\n",
    "            except: continue\n",
    "\n",
    "    if length and length > 0:\n",
    "        return round(width * length, 2)\n",
    "    return current_area\n",
    "\n",
    "# ================= 4. H√ÄM TR√çCH XU·∫§T S·ªê T·∫¶NG (FLOORS) - M·ªöI! =================\n",
    "def extract_floors(row):\n",
    "    text = str(row.get('Description', '')) + \" \" + str(row.get('Title', ''))\n",
    "    text = text.lower()\n",
    "    text = text.replace('t·∫•m', 't·∫ßng') # Chu·∫©n h√≥a\n",
    "\n",
    "    floors = 0\n",
    "    found_sDatture = False\n",
    "\n",
    "    # 4.1 Chi·∫øn thu·∫≠t c·ªông d·ªìn: Tr·ªát + L·∫ßu + L·ª≠ng + S√¢n th∆∞·ª£ng\n",
    "    matches_lau = re.findall(r'(\\d+)\\s*l·∫ßu', text)\n",
    "    if matches_lau:\n",
    "        num_lau = max([float(x) for x in matches_lau])\n",
    "        floors = num_lau + 1 # +1 cho t·∫ßng tr·ªát\n",
    "        found_sDatture = True\n",
    "    elif 'tr·ªát' in text and 'l·∫ßu' in text:\n",
    "        floors = 2 # M·∫∑c ƒë·ªãnh 1 tr·ªát 1 l·∫ßu\n",
    "        found_sDatture = True\n",
    "\n",
    "    if found_sDatture:\n",
    "        if 'l·ª≠ng' in text: floors += 0.5\n",
    "        if 's√¢n th∆∞·ª£ng' in text or 'chu·ªìng cu' in text or 'tum' in text: floors += 0.5\n",
    "        return floors\n",
    "\n",
    "    # 4.2 Chi·∫øn thu·∫≠t t√¨m s·ªë t·ªïng: \"3 t·∫ßng\", \"4 t·∫•m\"\n",
    "    match_tang = re.search(r'(\\d+)\\s*t·∫ßng', text)\n",
    "    if match_tang:\n",
    "        return float(match_tang.group(1))\n",
    "\n",
    "    # 4.3 C√°c tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát\n",
    "    if 'c·∫•p 4' in text or 'cap 4' in text: return 1.0\n",
    "    if 'g√°c' in text: return 1.5\n",
    "\n",
    "    return 1.0 # M·∫∑c ƒë·ªãnh b√®o nh·∫•t l√† 1 t·∫ßng\n",
    "\n",
    "# ================= CH·∫†Y CH∆Ø∆†NG TR√åNH =================\n",
    "print(\"ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t Width\n",
    "    print(\"- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang (Width)...\")\n",
    "    df['Width_m'] = df.apply(extract_width, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 2: C·ª®U D·ªÆ LI·ªÜU AREA\n",
    "    print(\"- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\")\n",
    "    df['Area_m2'] = df.apply(recover_missing_area, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 3: X√°c ƒë·ªãnh m·∫∑t ti·ªÅn\n",
    "    print(\"- ƒêang x√°c ƒë·ªãnh M·∫∑t ti·ªÅn (Is_MatTien)...\")\n",
    "    df['Is_MatTien'] = df.apply(check_mattien, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 4: Tr√≠ch xu·∫•t s·ªë t·∫ßng (M·ªöI)\n",
    "    print(\"- ƒêang ƒë·ªçc k·∫øt c·∫•u s·ªë t·∫ßng (Floors)...\")\n",
    "    df['Floors'] = df.apply(extract_floors, axis=1)\n",
    "\n",
    "    # B∆∞·ªõc 5: T√≠nh l·∫°i ƒë∆°n gi√°\n",
    "    print(\"- ƒêang c·∫≠p nh·∫≠t ƒë∆°n gi√° (Price_Per_m2)...\")\n",
    "    df['Price_Per_m2'] = df.apply(\n",
    "        lambda x: round((x['Price_Billion'] * 1000) / x['Area_m2'], 2)\n",
    "        if pd.notnull(x['Area_m2']) and x['Area_m2'] > 0 else 0,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"‚úÖ XONG! File k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # In ki·ªÉm tra m·∫´u\n",
    "    print(\"M·∫´u 5 d√≤ng d·ªØ li·ªáu (Width, Area, Floors, Price/m2):\")\n",
    "    print(df[['id', 'Width_m', 'Area_m2', 'Floors', 'Price_Per_m2']].head(10).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói: {e}\")"
   ],
   "id": "b6c394826c5e3f4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "- ƒêang tr√≠ch xu·∫•t chi·ªÅu ngang (Width)...\n",
      "- ƒêang t√≠nh to√°n ƒë·ªÉ l·∫•p ƒë·∫ßy Area b·ªã thi·∫øu...\n",
      "- ƒêang x√°c ƒë·ªãnh M·∫∑t ti·ªÅn (Is_MatTien)...\n",
      "- ƒêang ƒë·ªçc k·∫øt c·∫•u s·ªë t·∫ßng (Floors)...\n",
      "- ƒêang c·∫≠p nh·∫≠t ƒë∆°n gi√° (Price_Per_m2)...\n",
      "------------------------------\n",
      "‚úÖ XONG! File k·∫øt qu·∫£ ƒë·∫ßy ƒë·ªß: ../../data/merge/Quanthieudone3.csv\n",
      "------------------------------\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu (Width, Area, Floors, Price/m2):\n",
      "          id  Width_m  Area_m2  Floors  Price_Per_m2\n",
      "0  305927397      4.5     45.0     1.0         88.67\n",
      "1  306304969      4.0     36.0     1.0         50.00\n",
      "2  306316580      4.0     45.0     3.5         70.00\n",
      "3  105658348      9.0    277.0     7.0         79.42\n",
      "4  306031048      3.0     22.2     2.0        171.17\n",
      "5  305996311      3.0     20.0     4.0        250.00\n",
      "6  306060382     20.0     84.0     2.0         35.71\n",
      "7  305998797      NaN     36.6     2.0        100.82\n",
      "8  304760587      6.1     60.3     3.5        152.57\n",
      "9  306005353      5.0     40.0     5.0        207.50\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc Thi·∫øu Price_Per_m2, Thi·∫øu District, Gi√° qu√° r·∫ª (< 500 tri·ªáu), Width_m, tr√πng l·∫∑p, ƒêi·ªÅn khuy·∫øt th√¥ng minh: T·ª± ƒë·ªông t√≠nh Median s·ªë ph√≤ng ng·ªß/toilet c·ªßa t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn v√†o ch·ªó tr·ªëng c·ªßa Qu·∫≠n ƒë√≥.",
   "id": "6fb64e879ae9db89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:32:24.184662400Z",
     "start_time": "2026-01-05T15:32:23.983109200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# Input l√† file ƒë√£ t√≠nh to√°n xong ·ªü b∆∞·ªõc tr∆∞·ªõc\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone3.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone4.csv'\n",
    "\n",
    "try:\n",
    "    print(\"‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    n_original = len(df)\n",
    "    print(f\"--> T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: {n_original}\")\n",
    "\n",
    "    # ================= B∆Ø·ªöC 1: THANH L·ªåC D·ªÆ LI·ªÜU (FILTERING) =================\n",
    "\n",
    "    # 1.1 X√≥a c√°c d√≤ng b·ªã thi·∫øu th√¥ng tin CH√ç M·∫†NG (Critical Missing)\n",
    "    # Th√™m 'Area_m2' v√†o ƒë√¢y ƒë·ªÉ lo·∫°i b·ªè ngay 49 d√≤ng b·ªã l·ªói di·ªán t√≠ch\n",
    "    critical_cols = ['Price_Per_m2', 'District', 'Width_m', 'Area_m2']\n",
    "    df = df.dropna(subset=critical_cols)\n",
    "\n",
    "    # L·ªçc th√™m: ƒê·∫£m b·∫£o ƒë∆°n gi√° ph·∫£i > 0 (tr√°nh l·ªói chia cho 0 c√≤n s√≥t)\n",
    "    df = df[df['Price_Per_m2'] > 0]\n",
    "\n",
    "    print(f\"- Sau khi x√≥a thi·∫øu Gi√°/Qu·∫≠n/Chi·ªÅu ngang/Di·ªán t√≠ch: {len(df)}\")\n",
    "\n",
    "    # 1.2 L·ªçc theo Gi√° tr·ªã (Price Billion)\n",
    "    # Y√™u c·∫ßu: Gi√° qu√° r·∫ª (< 500 tri·ªáu hay 0.5 t·ª∑) -> X√ìA\n",
    "    df = df[df['Price_Billion'] >= 0.5]\n",
    "    print(f\"- Sau khi x√≥a nh√† < 500 tri·ªáu: {len(df)}\")\n",
    "\n",
    "    # 1.3 X·ª≠ l√Ω tr√πng l·∫∑p (Duplicates)\n",
    "    # Logic: N·∫øu Ti√™u ƒë·ªÅ, Gi√°, Di·ªán t√≠ch v√† Qu·∫≠n gi·ªëng h·ªát nhau -> Coi l√† spam -> X√ìA\n",
    "    df = df.drop_duplicates(subset=['Title', 'Price_Billion', 'Area_m2', 'District'])\n",
    "    print(f\"- Sau khi x√≥a tin Spam tr√πng l·∫∑p: {len(df)}\")\n",
    "\n",
    "    # *L∆ØU √ù: C√°c ƒëi·ªÅu ki·ªán Di·ªán t√≠ch <10, >500, Gi√° ·∫£o >800 -> KH√îNG L·ªåC (Theo y√™u c·∫ßu)*\n",
    "\n",
    "    # ================= B∆Ø·ªöC 2: ƒêI·ªÄN KHUY·∫æT TH√îNG MINH (GROUP IMPUTATION) =================\n",
    "    # Y√™u c·∫ßu: D√πng Median (Trung v·ªã) c·ªßa t·ª´ng QU·∫¨N ƒë·ªÉ ƒëi·ªÅn v√†o Bedrooms/Toilets b·ªã thi·∫øu\n",
    "\n",
    "    print(\"\\n‚è≥ ƒêang t√≠nh to√°n Median theo t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn khuy·∫øt...\")\n",
    "\n",
    "    # H√†m ƒëi·ªÅn median theo nh√≥m\n",
    "    def fill_na_with_district_median(df, target_col, group_col='District'):\n",
    "        # T√≠nh median cho t·ª´ng nh√≥m (Qu·∫≠n)\n",
    "        median_series = df.groupby(group_col)[target_col].transform('median')\n",
    "\n",
    "        # ƒêi·ªÅn c√°c √¥ NaN b·∫±ng gi√° tr·ªã median v·ª´a t√≠nh\n",
    "        df[target_col] = df[target_col].fillna(median_series)\n",
    "\n",
    "        # \"Ch·ªØa ch√°y\": N·∫øu c·∫£ Qu·∫≠n ƒë√≥ kh√¥ng c√≥ d·ªØ li·ªáu n√†o (hi·∫øm), d√πng Median to√†n th√†nh ph·ªë\n",
    "        global_median = df[target_col].median()\n",
    "        df[target_col] = df[target_col].fillna(global_median)\n",
    "\n",
    "        # L√†m tr√≤n s·ªë (v√¨ ph√≤ng ng·ªß/toilet ph·∫£i l√† s·ªë nguy√™n)\n",
    "        df[target_col] = df[target_col].round()\n",
    "        return df\n",
    "\n",
    "    # Th·ª±c hi·ªán ƒëi·ªÅn cho Bedrooms & Toilets\n",
    "    df = fill_na_with_district_median(df, 'Bedrooms')\n",
    "    df = fill_na_with_district_median(df, 'Toilets')\n",
    "\n",
    "        # ================= B∆Ø·ªöC 3: KI·ªÇM TRA CU·ªêI C√ôNG & L∆ØU FILE =================\n",
    "\n",
    "    print(\"\\n‚è≥ ƒêang l∆∞u file k·∫øt qu·∫£...\")\n",
    "\n",
    "    # L∆∞u file CSV\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU\")\n",
    "    print(f\"üìÅ File k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "    print(f\"üìä S·ªë l∆∞·ª£ng d√≤ng c√≤n l·∫°i: {len(df)} \"\n",
    "          f\"(Gi·ªØ l·∫°i {round(len(df)/n_original*100, 1)}% d·ªØ li·ªáu g·ªëc)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ================= DEMO PH·ª§C V·ª§ B√ÅO C√ÅO =================\n",
    "    print(\"\\n[Demo B√°o C√°o] Ki·ªÉm tra d·ªØ li·ªáu Qu·∫≠n G√≤ V·∫•p sau khi ƒëi·ªÅn Median:\")\n",
    "\n",
    "    sample = df[df['District'].str.contains('G√≤ V·∫•p', na=False, case=False)]\n",
    "    if not sample.empty:\n",
    "        print(sample[['District', 'Bedrooms', 'Toilets']].head(5).to_string())\n",
    "    else:\n",
    "        print(\"(Kh√¥ng c√≥ d·ªØ li·ªáu G√≤ V·∫•p ‚Äì in 5 d√≤ng b·∫•t k·ª≥)\")\n",
    "        print(df[['District', 'Bedrooms', 'Toilets']].head(5).to_string())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå C√ì L·ªñI X·∫¢Y RA TRONG QU√Å TR√åNH X·ª¨ L√ù!\")\n",
    "    print(f\"üëâ Chi ti·∫øt l·ªói: {e}\")\n"
   ],
   "id": "fa265f5a35219d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc d·ªØ li·ªáu...\n",
      "--> T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: 3424\n",
      "- Sau khi x√≥a thi·∫øu Gi√°/Qu·∫≠n/Chi·ªÅu ngang/Di·ªán t√≠ch: 1871\n",
      "- Sau khi x√≥a nh√† < 500 tri·ªáu: 1869\n",
      "- Sau khi x√≥a tin Spam tr√πng l·∫∑p: 1849\n",
      "\n",
      "‚è≥ ƒêang t√≠nh to√°n Median theo t·ª´ng Qu·∫≠n ƒë·ªÉ ƒëi·ªÅn khuy·∫øt...\n",
      "\n",
      "‚è≥ ƒêang l∆∞u file k·∫øt qu·∫£...\n",
      "--------------------------------------------------\n",
      "‚úÖ HO√ÄN T·∫§T X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
      "üìÅ File k·∫øt qu·∫£: ../../data/merge/Quanthieudone4.csv\n",
      "üìä S·ªë l∆∞·ª£ng d√≤ng c√≤n l·∫°i: 1849 (Gi·ªØ l·∫°i 54.0% d·ªØ li·ªáu g·ªëc)\n",
      "--------------------------------------------------\n",
      "\n",
      "[Demo B√°o C√°o] Ki·ªÉm tra d·ªØ li·ªáu Qu·∫≠n G√≤ V·∫•p sau khi ƒëi·ªÅn Median:\n",
      "(Kh√¥ng c√≥ d·ªØ li·ªáu G√≤ V·∫•p ‚Äì in 5 d√≤ng b·∫•t k·ª≥)\n",
      "  District  Bedrooms  Toilets\n",
      "0   Qu·∫≠n 4       3.0      3.0\n",
      "1   Qu·∫≠n 4       3.0      3.0\n",
      "2   Qu·∫≠n 4       3.0      3.0\n",
      "3   Qu·∫≠n 4       6.0      6.0\n",
      "4   Qu·∫≠n 4       1.0      1.0\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "T·ª´ title + description => ph∆∞·ªùng(ward)",
   "id": "b2f5a65d6f854c89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:33:07.873484500Z",
     "start_time": "2026-01-05T15:33:07.606602600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone4.csv'\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone5.csv'\n",
    "\n",
    "# 1. T·ª™ ƒêI·ªÇN PH∆Ø·ªúNG/X√É (ƒê√£ t√°ch ri√™ng Q2, Q9, Th·ªß ƒê·ª©c ƒë·ªÉ chu·∫©n x√°c h∆°n)\n",
    "hcm_wards_advanced = {\n",
    "    'Qu·∫≠n 1': ['B·∫øn Ngh√©', 'B·∫øn Th√†nh', 'C√¥ Giang', 'C·∫ßu Kho', 'C·∫ßu √îng L√£nh', 'ƒêa Kao', 'Nguy·ªÖn C∆∞ Trinh', 'Nguy·ªÖn Th√°i B√¨nh', 'Ph·∫°m Ng≈© L√£o', 'T√¢n ƒê·ªãnh'],\n",
    "    'Qu·∫≠n 3': ['1', '2', '3', '4', '5', '9', '10', '11', '12', '14', 'V√µ Th·ªã S√°u', '6', '7', '8'],\n",
    "    'Qu·∫≠n 4': ['1', '2', '3', '4', '6', '8', '9', '10', '13', '14', '15', '16', '18', '12'],\n",
    "    'Qu·∫≠n 5': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'],\n",
    "    'Qu·∫≠n 6': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14'],\n",
    "    'Qu·∫≠n 7': ['B√¨nh Thu·∫≠n', 'Ph√∫ M·ªπ', 'Ph√∫ Thu·∫≠n', 'T√¢n H∆∞ng', 'T√¢n Ki·ªÉng', 'T√¢n Phong', 'T√¢n Ph√∫', 'T√¢n Quy', 'T√¢n Thu·∫≠n ƒê√¥ng', 'T√¢n Thu·∫≠n T√¢y'],\n",
    "    'Qu·∫≠n 8': ['1', '2', '3', '4', '5', '6', '8', '7', '9', '10', '11', '12', '13', '14', '15', '16'],\n",
    "    'Qu·∫≠n 10': ['1', '2', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '3'],\n",
    "    'Qu·∫≠n 11': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16'],\n",
    "    'Qu·∫≠n 12': ['An Ph√∫ ƒê√¥ng', 'ƒê√¥ng H∆∞ng Thu·∫≠n', 'Hi·ªáp Th√†nh', 'T√¢n Ch√°nh Hi·ªáp', 'T√¢n H∆∞ng Thu·∫≠n', 'T√¢n Th·ªõi Hi·ªáp', 'T√¢n Th·ªõi Nh·∫•t', 'Th·∫°nh L·ªôc', 'Th·∫°nh Xu√¢n', 'Th·ªõi An', 'Trung M·ªπ T√¢y'],\n",
    "    'B√¨nh Th·∫°nh': ['1', '2', '3', '5', '6', '7', '11', '12', '13', '14', '15', '17', '19', '21', '22', '24', '25', '26', '27', '28'],\n",
    "    'G√≤ V·∫•p': ['1', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17'],\n",
    "    'Ph√∫ Nhu·∫≠n': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11', '13', '15', '17'],\n",
    "    'T√¢n B√¨nh': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'],\n",
    "    'T√¢n Ph√∫': ['Hi·ªáp T√¢n', 'H√≤a Th·∫°nh', 'Ph√∫ Th·ªç H√≤a', 'Ph√∫ Th·∫°nh', 'Ph√∫ Trung', 'S∆°n K·ª≥', 'T√¢n Qu√Ω', 'T√¢n S∆°n Nh√¨', 'T√¢n Th√†nh', 'T√¢n Th·ªõi H√≤a', 'T√¢y Th·∫°nh'],\n",
    "    'B√¨nh T√¢n': ['An L·∫°c', 'An L·∫°c A', 'B√¨nh H∆∞ng H√≤a', 'B√¨nh H∆∞ng H√≤a A', 'B√¨nh H∆∞ng H√≤a B', 'B√¨nh Tr·ªã ƒê√¥ng', 'B√¨nh Tr·ªã ƒê√¥ng A', 'B√¨nh Tr·ªã ƒê√¥ng B', 'T√¢n T·∫°o', 'T√¢n T·∫°o A'],\n",
    "\n",
    "    # Khu v·ª±c TP Th·ªß ƒê·ª©c (T√°ch ra ƒë·ªÉ ch√≠nh x√°c)\n",
    "    'Th·ªß ƒê·ª©c': ['B√¨nh Chi·ªÉu', 'B√¨nh Th·ªç', 'Hi·ªáp B√¨nh Ch√°nh', 'Hi·ªáp B√¨nh Ph∆∞·ªõc', 'Linh Chi·ªÉu', 'Linh ƒê√¥ng', 'Linh T√¢y', 'Linh Trung', 'Linh Xu√¢n', 'Tam B√¨nh', 'Tam Ph√∫', 'Tr∆∞·ªùng Th·ªç'],\n",
    "    'Qu·∫≠n 2': ['An Kh√°nh', 'An L·ª£i ƒê√¥ng', 'An Ph√∫', 'B√¨nh An', 'B√¨nh Kh√°nh', 'B√¨nh Tr∆∞ng ƒê√¥ng', 'B√¨nh Tr∆∞ng T√¢y', 'C√°t L√°i', 'Th·∫°nh M·ªπ L·ª£i', 'Th·∫£o ƒêi·ªÅn', 'Th·ªß Thi√™m'],\n",
    "    'Qu·∫≠n 9': ['Hi·ªáp Ph√∫', 'Long B√¨nh', 'Long Ph∆∞·ªõc', 'Long Th·∫°nh M·ªπ', 'Long Tr∆∞·ªùng', 'Ph√∫ H·ªØu', 'Ph∆∞·ªõc B√¨nh', 'Ph∆∞·ªõc Long A', 'Ph∆∞·ªõc Long B', 'T√¢n Ph√∫', 'TƒÉng Nh∆°n Ph√∫ A', 'TƒÉng Nh∆°n Ph√∫ B'],\n",
    "\n",
    "    # Huy·ªán\n",
    "    'C·ªß Chi': ['An Nh∆°n T√¢y', 'B√¨nh M·ªπ', 'H√≤a Ph√∫', 'Nhu·∫≠n ƒê·ª©c', 'Ph·∫°m VƒÉn C·ªôi', 'Ph√∫ H√≤a ƒê√¥ng', 'Ph√∫ M·ªπ H∆∞ng', 'Ph∆∞·ªõc Hi·ªáp', 'Ph∆∞·ªõc Th·∫°nh', 'Ph∆∞·ªõc Vƒ©nh An', 'T√¢n An H·ªôi', 'T√¢n Ph√∫ Trung', 'T√¢n Th·∫°nh ƒê√¥ng', 'T√¢n Th·∫°nh T√¢y', 'T√¢n Th√¥ng H·ªôi', 'Th√°i M·ªπ', 'Trung An', 'Trung L·∫≠p H·∫°', 'Trung L·∫≠p Th∆∞·ª£ng', 'C·ªß Chi', 'Th·ªã tr·∫•n C·ªß Chi'],\n",
    "    'H√≥c M√¥n': ['B√† ƒêi·ªÉm', 'ƒê√¥ng Th·∫°nh', 'Nh·ªã B√¨nh', 'T√¢n Hi·ªáp', 'T√¢n Th·ªõi Nh√¨', 'T√¢n Xu√¢n', 'Th·ªõi Tam Th√¥n', 'Trung Ch√°nh', 'Xu√¢n Th·ªõi ƒê√¥ng', 'Xu√¢n Th·ªõi S∆°n', 'Xu√¢n Th·ªõi Th∆∞·ª£ng', 'H√≥c M√¥n', 'Th·ªã tr·∫•n H√≥c M√¥n'],\n",
    "    'B√¨nh Ch√°nh': ['An Ph√∫ T√¢y', 'B√¨nh Ch√°nh', 'B√¨nh H∆∞ng', 'B√¨nh L·ª£i', 'ƒêa Ph∆∞·ªõc', 'H∆∞ng Long', 'L√™ Minh Xu√¢n', 'Ph·∫°m VƒÉn Hai', 'Phong Ph√∫', 'Quy ƒê·ª©c', 'T√¢n Ki√™n', 'T√¢n Nh·ª±t', 'T√¢n Qu√Ω T√¢y', 'Vƒ©nh L·ªôc A', 'Vƒ©nh L·ªôc B', 'T√¢n T√∫c', 'Th·ªã tr·∫•n T√¢n T√∫c'],\n",
    "    'Nh√† B√®': ['Hi·ªáp Ph∆∞·ªõc', 'Long Th·ªõi', 'Nh∆°n ƒê·ª©c', 'Ph√∫ Xu√¢n', 'Ph∆∞·ªõc Ki·ªÉn', 'Ph∆∞·ªõc L·ªôc', 'Nh√† B√®', 'Th·ªã tr·∫•n Nh√† B√®'],\n",
    "    'C·∫ßn Gi·ªù': ['An Th·ªõi ƒê√¥ng', 'B√¨nh Kh√°nh', 'Long H√≤a', 'L√Ω Nh∆°n', 'Tam Th√¥n Hi·ªáp', 'Th·∫°nh An', 'C·∫ßn Th·∫°nh', 'Th·ªã tr·∫•n C·∫ßn Th·∫°nh']\n",
    "}\n",
    "\n",
    "# 2. MAPPING S√ÅP NH·∫¨P (QUAN TR·ªåNG: MAP M·ªöI V·ªÄ C≈®)\n",
    "# C·∫•u tr√∫c: ('Qu·∫≠n', 'T√™n M·ªõi'): 'T√™n C≈© ƒê·∫°i Di·ªán'\n",
    "merged_ward_mapping = {\n",
    "    # G√≤ V·∫•p: H·∫°nh Th√¥ng = P1 + P3 (Ch·ªçn P1)\n",
    "    ('G√≤ V·∫•p', 'H·∫°nh Th√¥ng'): '1',\n",
    "    ('G√≤ V·∫•p', 'Ph∆∞·ªùng H·∫°nh Th√¥ng'): '1',\n",
    "\n",
    "    # Qu·∫≠n 3: V√µ Th·ªã S√°u = P6 + P7 + P8 (Ch·ªçn P6)\n",
    "    ('Qu·∫≠n 3', 'V√µ Th·ªã S√°u'): '6',\n",
    "\n",
    "    # Qu·∫≠n 2 (Th·ªß ƒê·ª©c): An Kh√°nh m·ªõi = B√¨nh An + B√¨nh Kh√°nh (Ch·ªçn B√¨nh An)\n",
    "    ('Qu·∫≠n 2', 'An Kh√°nh'): 'B√¨nh An',\n",
    "    ('Th·ªß ƒê·ª©c', 'An Kh√°nh'): 'B√¨nh An',\n",
    "\n",
    "    # Qu·∫≠n 4: P12 nh·∫≠p v√†o P13\n",
    "    ('Qu·∫≠n 4', '12'): '13',\n",
    "\n",
    "    # Qu·∫≠n 5: P15 nh·∫≠p v√†o P12\n",
    "    ('Qu·∫≠n 5', '15'): '12',\n",
    "\n",
    "    # Qu·∫≠n 10: P3 nh·∫≠p v√†o P2\n",
    "    ('Qu·∫≠n 10', '3'): '2',\n",
    "\n",
    "    # Ph√∫ Nhu·∫≠n: P12 -> P11, P14 -> P13 (V√≠ d·ª•)\n",
    "    ('Ph√∫ Nhu·∫≠n', '12'): '11',\n",
    "    ('Ph√∫ Nhu·∫≠n', '14'): '13'\n",
    "}\n",
    "\n",
    "def normalize_district_key(district_raw):\n",
    "    if pd.isna(district_raw): return None\n",
    "    d = str(district_raw).strip()\n",
    "    if d in ['Q2', 'Q.2', 'Qu·∫≠n 2', 'District 2']: return 'Qu·∫≠n 2'\n",
    "    if d in ['Q9', 'Q.9', 'Qu·∫≠n 9', 'District 9']: return 'Qu·∫≠n 9'\n",
    "    if d in ['Th·ªß ƒê·ª©c', 'Q.Th·ªß ƒê·ª©c', 'TP Th·ªß ƒê·ª©c', 'Th√†nh ph·ªë Th·ªß ƒê·ª©c']: return 'Th·ªß ƒê·ª©c'\n",
    "    if d in hcm_wards_advanced: return d\n",
    "    if d.startswith('Q') and d[1:].isdigit(): return f\"Qu·∫≠n {d[1:]}\"\n",
    "    if d.startswith('Q.') and d[2:].isdigit(): return f\"Qu·∫≠n {d[2:]}\"\n",
    "    return d\n",
    "\n",
    "def extract_ward(row):\n",
    "    district_key = normalize_district_key(row['District'])\n",
    "    if not district_key: return None\n",
    "\n",
    "    # G·ªôp text ƒë·ªÉ t√¨m ki·∫øm\n",
    "    text_search = (str(row.get('Title', '')) + ' ' + str(row.get('Description', '')) + ' ' + str(row.get('Address', ''))).lower()\n",
    "\n",
    "    # --- ∆ØU TI√äN 1: CHECK MAPPING S√ÅP NH·∫¨P (T√äN M·ªöI) ---\n",
    "    for (dist, new_ward), old_ward_target in merged_ward_mapping.items():\n",
    "        # Ki·ªÉm tra ƒë√∫ng qu·∫≠n (ho·∫∑c qu·∫≠n thu·ªôc nh√≥m Th·ªß ƒê·ª©c)\n",
    "        is_match_district = (dist == district_key) or \\\n",
    "                            (district_key == 'Th·ªß ƒê·ª©c' and dist in ['Qu·∫≠n 2', 'Qu·∫≠n 9', 'Th·ªß ƒê·ª©c'])\n",
    "\n",
    "        if is_match_district:\n",
    "            # N·∫øu t√¨m th·∫•y t√™n ph∆∞·ªùng m·ªõi (VD: \"H·∫°nh Th√¥ng\") trong vƒÉn b·∫£n\n",
    "            if new_ward.lower() in text_search:\n",
    "                return old_ward_target # Tr·∫£ v·ªÅ t√™n c≈© (VD: \"1\")\n",
    "\n",
    "    # --- ∆ØU TI√äN 2: T√åM KI·∫æM B√åNH TH∆Ø·ªúNG ---\n",
    "    possible_wards = []\n",
    "    if district_key in hcm_wards_advanced:\n",
    "        possible_wards = hcm_wards_advanced[district_key]\n",
    "    elif district_key in ['Th√†nh ph·ªë Th·ªß ƒê·ª©c', 'TP. Th·ªß ƒê·ª©c']:\n",
    "         # N·∫øu input ch·ªâ ghi chung l√† TP Th·ªß ƒê·ª©c, ta t√¨m trong c·∫£ 3 qu·∫≠n c≈©\n",
    "         possible_wards = hcm_wards_advanced['Th·ªß ƒê·ª©c'] + hcm_wards_advanced['Qu·∫≠n 2'] + hcm_wards_advanced['Qu·∫≠n 9']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # T√¨m Ph∆∞·ªùng S·ªë (P1, F.1, Ph∆∞·ªùng 1...)\n",
    "    numeric_wards = [w for w in possible_wards if w.isdigit()]\n",
    "    for ward in numeric_wards:\n",
    "        # Regex th√¥ng minh: b·∫Øt p, f, ph∆∞·ªùng + s·ªë + kh√¥ng c√≥ s·ªë ƒë·∫±ng sau\n",
    "        pattern = r'(?:ph∆∞·ªùng|p|f)[\\.\\s]*0?' + ward + r'(?!\\d)'\n",
    "        if re.search(pattern, text_search):\n",
    "            return ward\n",
    "\n",
    "    # T√¨m Ph∆∞·ªùng Ch·ªØ (T√¢n ƒê·ªãnh, ƒêa Kao...)\n",
    "    named_wards = [w for w in possible_wards if not w.isdigit()]\n",
    "    named_wards.sort(key=len, reverse=True) # T√¨m t√™n d√†i tr∆∞·ªõc\n",
    "\n",
    "    for ward in named_wards:\n",
    "        if ward.lower() in text_search:\n",
    "            return ward\n",
    "\n",
    "    return None\n",
    "\n",
    "# --- CH·∫†Y CH∆Ø∆†NG TR√åNH ---\n",
    "print(\"ƒêang x·ª≠ l√Ω tr√≠ch xu·∫•t Ph∆∞·ªùng (Advanced Mapping)...\")\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    df['Ward'] = df.apply(extract_ward, axis=1)\n",
    "\n",
    "    # Th·ªëng k√™\n",
    "    total = len(df)\n",
    "    found = df['Ward'].notna().sum()\n",
    "    print(f\"T·ªïng s·ªë d√≤ng: {total}\")\n",
    "    print(f\"T√¨m th·∫•y Ph∆∞·ªùng: {found} ({found/total*100:.2f}%)\")\n",
    "    print(\"-\" * 30)\n",
    "    print(df[['District', 'Ward']].head(10))\n",
    "\n",
    "    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(f\"ƒê√£ l∆∞u file k·∫øt qu·∫£: {OUTPUT_FILE}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói: {e}\")"
   ],
   "id": "581118ccf5bd6373",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω tr√≠ch xu·∫•t Ph∆∞·ªùng (Advanced Mapping)...\n",
      "T·ªïng s·ªë d√≤ng: 1849\n",
      "T√¨m th·∫•y Ph∆∞·ªùng: 1355 (73.28%)\n",
      "------------------------------\n",
      "  District  Ward\n",
      "0   Qu·∫≠n 4     8\n",
      "1   Qu·∫≠n 4     4\n",
      "2   Qu·∫≠n 4    15\n",
      "3   Qu·∫≠n 4    16\n",
      "4   Qu·∫≠n 4    13\n",
      "5   Qu·∫≠n 4  None\n",
      "6   Qu·∫≠n 4    10\n",
      "7   Qu·∫≠n 4     4\n",
      "8   Qu·∫≠n 4     4\n",
      "9   Qu·∫≠n 4     1\n",
      "ƒê√£ l∆∞u file k·∫øt qu·∫£: ../../data/merge/Quanthieudone5.csv\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc ch·ªâ l·∫•y nh·ªØng c·ªôt c√≥ tr∆∞·ªùng Ward kh√¥ng null\n",
   "id": "5b29b3ff49811b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:33:28.383610400Z",
     "start_time": "2026-01-05T15:33:28.111365800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone5.csv'  # File v·ª´a ch·∫°y xong ·ªü b∆∞·ªõc tr∆∞·ªõc\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieudone6.csv'  # File S·∫†CH S·∫º (Ch·ªâ ch·ª©a data c√≥ Ward)\n",
    "\n",
    "try:\n",
    "    print(f\"‚è≥ ƒêang ƒë·ªçc file '{INPUT_FILE}'...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    initial_count = len(df)\n",
    "\n",
    "    # 1. L·ªåC D·ªÆ LI·ªÜU\n",
    "    # Gi·ªØ l·∫°i c√°c d√≤ng m√† c·ªôt 'Ward' KH√îNG b·ªã r·ªóng (notna)\n",
    "    df_valid = df[df['Ward'].notna()]\n",
    "\n",
    "    # 2. L∆ØU FILE\n",
    "    df_valid.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # 3. B√ÅO C√ÅO K·∫æT QU·∫¢\n",
    "    valid_count = len(df_valid)\n",
    "    dropped_count = initial_count - valid_count\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚úÖ ƒê√É XU·∫§T TH√ÄNH C√îNG FILE: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"üìä T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: {initial_count}\")\n",
    "    print(f\"üü¢ S·ªë d√≤ng H·ª¢P L·ªÜ (C√≥ Ph∆∞·ªùng): {valid_count} d√≤ng\")\n",
    "    print(f\"üî¥ S·ªë d√≤ng B·ªä LO·∫†I (Null Ph∆∞·ªùng): {dropped_count} d√≤ng\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # In m·∫´u ƒë·ªÉ ki·ªÉm tra\n",
    "    print(\"\\nM·∫´u 5 d√≤ng d·ªØ li·ªáu chu·∫©n ƒë√£ l·ªçc:\")\n",
    "    print(df_valid[['District', 'Ward', 'Title']].head(5).to_string())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. B·∫°n h√£y ch·∫Øc ch·∫Øn ƒë√£ ch·∫°y code tr√≠ch xu·∫•t Ph∆∞·ªùng ·ªü b∆∞·ªõc tr∆∞·ªõc.\")\n",
    "except KeyError:\n",
    "    print(\"‚ùå L·ªói: File kh√¥ng c√≥ c·ªôt 'Ward'. H√£y ki·ªÉm tra l·∫°i.\")"
   ],
   "id": "39b0772b74dd1a16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc file '../../data/merge/Quanthieudone5.csv'...\n",
      "--------------------------------------------------\n",
      "‚úÖ ƒê√É XU·∫§T TH√ÄNH C√îNG FILE: ../../data/merge/Quanthieudone6.csv\n",
      "--------------------------------------------------\n",
      "üìä T·ªïng s·ªë d√≤ng ban ƒë·∫ßu: 1849\n",
      "üü¢ S·ªë d√≤ng H·ª¢P L·ªÜ (C√≥ Ph∆∞·ªùng): 1355 d√≤ng\n",
      "üî¥ S·ªë d√≤ng B·ªä LO·∫†I (Null Ph∆∞·ªùng): 494 d√≤ng\n",
      "--------------------------------------------------\n",
      "\n",
      "M·∫´u 5 d√≤ng d·ªØ li·ªáu chu·∫©n ƒë√£ l·ªçc:\n",
      "  District  Ward                                                                                    Title\n",
      "0   Qu·∫≠n 4   8.0  C·∫ßn ti·ªÅn b√°n g·∫•p nh√† ri√™ng gi√° si√™u h·ªùi t·∫°i Vƒ©nh Kh√°nh, Ph∆∞·ªùng 8, Qu·∫≠n 4, 3,99 t·ª∑, 45m2\n",
      "1   Qu·∫≠n 4   4.0                        Si√™u ph·∫©m nh√† 35m¬≤ ngay tr·ª•c ƒë∆∞·ªùng Ng√¥ Gia T·ª±, Qu·∫≠n 4, gi√° 1,8 t·ª∑\n",
      "2   Qu·∫≠n 4  15.0                                          Ch·ªß ƒëi M·ªπ ƒë·ªãnh c∆∞ c·∫ßn b√°n nh√† ƒë∆∞·ªùng ƒêo√†n VƒÉn B∆°\n",
      "3   Qu·∫≠n 4  16.0     BaÃÅn nhaÃÄ h·∫ªm xe h∆°i T√¥n Th√¢ÃÅt Thuy√™ÃÅt, Ph∆∞∆°ÃÄng 16, Qu·∫≠n 4, 277m2, 2 t√¢ÃÄng, giaÃÅ reÃâ\n",
      "4   Qu·∫≠n 4  13.0                 Nh√† 2 t·∫•m ƒë·∫πp nh∆∞ m∆°, h·∫ªm xe h∆°i 3m, Qu·∫≠n 4, gi√° h·ªùi cho ng∆∞·ªùi nhanh tay\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "L·ªçc ra c√°c tr∆∞·ªùng c·∫ßn thi·∫øt",
   "id": "d67df8152ad19b53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:33:52.223090300Z",
     "start_time": "2026-01-05T15:33:52.141509500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "INPUT_FILE = '../../data/merge/Quanthieudone6.csv'  # File ƒë√£ c√≥ ƒë·ªß Ph∆∞·ªùng\n",
    "OUTPUT_FILE = '../../data/merge/Quanthieu_done.csv'  # File k·∫øt qu·∫£\n",
    "\n",
    "try:\n",
    "    print(f\"‚è≥ ƒêang ƒë·ªçc file '{INPUT_FILE}'...\")\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # 1. X·ª¨ L√ù C·ªòT \"IS HEM\" (T·∫°o t·ª´ Is_MatTien)\n",
    "    # Logic: N·∫øu Is_MatTien = 0 th√¨ Is Hem = 1\n",
    "    if 'Is Hem' not in df.columns:\n",
    "        print(\"- ƒêang t·∫°o c·ªôt 'Is Hem'...\")\n",
    "        df['Is Hem'] = df['Is_MatTien'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "    # 2. X·ª¨ L√ù C·ªòT \"POST TIME\"\n",
    "    # Trong code c≈© t√™n l√† 'Post_Time' (c√≥ g·∫°ch d∆∞·ªõi), n·∫øu b·∫°n mu·ªën t√™n l√† 'Post Time' (c√≥ d·∫•u c√°ch) th√¨ ƒë·ªïi l·∫°i\n",
    "    if 'Post_Time' in df.columns:\n",
    "        df.rename(columns={'Post_Time': 'Post Time'}, inplace=True)\n",
    "\n",
    "    # 3. DANH S√ÅCH 12 C·ªòT B·∫†N Y√äU C·∫¶U\n",
    "    target_cols = [\n",
    "        'Price_Billion',\n",
    "        'Price_Per_m2',\n",
    "        'Area_m2',\n",
    "        'District',\n",
    "        'Ward',\n",
    "        'Bedrooms',\n",
    "        'Is_MatTien',\n",
    "        'Width_m',\n",
    "        'Floors',\n",
    "        'Is Hem',\n",
    "        'Post Time',\n",
    "        'Toilets'\n",
    "    ]\n",
    "\n",
    "    # 4. TH·ª∞C HI·ªÜN L·ªåC V√Ä L∆ØU FILE\n",
    "    # Ch·ªâ l·∫•y ƒë√∫ng c√°c c·ªôt trong danh s√°ch\n",
    "    df_final = df[target_cols]\n",
    "\n",
    "    df_final.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚úÖ ƒê√É XONG! File ch·ªâ ch·ª©a ƒë√∫ng 12 c·ªôt: {OUTPUT_FILE}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(df_final.head().to_string())\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt {e} trong file g·ªëc. H√£y ki·ªÉm tra l·∫°i t√™n c·ªôt.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói: {e}\")"
   ],
   "id": "c2ff62bdc74e2bec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang ƒë·ªçc file '../../data/merge/Quanthieudone6.csv'...\n",
      "- ƒêang t·∫°o c·ªôt 'Is Hem'...\n",
      "--------------------------------------------------\n",
      "‚úÖ ƒê√É XONG! File ch·ªâ ch·ª©a ƒë√∫ng 12 c·ªôt: ../../data/merge/Quanthieu_done.csv\n",
      "--------------------------------------------------\n",
      "   Price_Billion  Price_Per_m2  Area_m2 District  Ward  Bedrooms  Is_MatTien  Width_m  Floors  Is Hem   Post Time  Toilets\n",
      "0           3.99         88.67     45.0   Qu·∫≠n 4   8.0       3.0           1      4.5     1.0       0  04/01/2026      3.0\n",
      "1           1.80         50.00     36.0   Qu·∫≠n 4   4.0       3.0           1      4.0     1.0       0  31/12/2025      3.0\n",
      "2           3.15         70.00     45.0   Qu·∫≠n 4  15.0       3.0           1      4.0     3.5       0  30/12/2025      3.0\n",
      "3          22.00         79.42    277.0   Qu·∫≠n 4  16.0       6.0           0      9.0     7.0       1  30/12/2025      6.0\n",
      "4           3.80        171.17     22.2   Qu·∫≠n 4  13.0       1.0           0      3.0     2.0       1  30/12/2025      1.0\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:34:27.850149800Z",
     "start_time": "2026-01-05T15:34:27.693499600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def inspect_csv(df):\n",
    "    print(\"===== CSV OVERVIEW =====\")\n",
    "    print(f\"Rows    : {df.shape[0]}\")\n",
    "    print(f\"Columns : {df.shape[1]}\")\n",
    "    print(\"\\n--- Data types ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Memory usage ---\")\n",
    "    print(round(df.memory_usage(deep=True).sum() / 1024 ** 2, 2), \"MB\")\n",
    "\n",
    "\n",
    "df_raw = pd.read_csv('../../data/merge/Quanthieu_done.csv')\n",
    "inspect_csv(df_raw)\n"
   ],
   "id": "8182ee9957157e3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== CSV OVERVIEW =====\n",
      "Rows    : 1355\n",
      "Columns : 12\n",
      "\n",
      "--- Data types ---\n",
      "Price_Billion    float64\n",
      "Price_Per_m2     float64\n",
      "Area_m2          float64\n",
      "District          object\n",
      "Ward             float64\n",
      "Bedrooms         float64\n",
      "Is_MatTien         int64\n",
      "Width_m          float64\n",
      "Floors           float64\n",
      "Is Hem             int64\n",
      "Post Time         object\n",
      "Toilets          float64\n",
      "dtype: object\n",
      "\n",
      "--- Memory usage ---\n",
      "0.28 MB\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T15:34:32.428191200Z",
     "start_time": "2026-01-05T15:34:32.286428800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def report_missing_values(df):\n",
    "    print(\"===== MISSING VALUE REPORT =====\")\n",
    "    missing = df.isna().sum()\n",
    "    percent = (missing / len(df)) * 100\n",
    "    report = pd.DataFrame({\n",
    "        \"Missing_Count\": missing,\n",
    "        \"Percent_Missing (%)\": percent.round(2)\n",
    "    }).sort_values(by=\"Missing_Count\", ascending=False)\n",
    "    print(report)\n",
    "    return report\n",
    "\n",
    "\n",
    "report_missing_values(df_raw)"
   ],
   "id": "b68e9d33b916e891",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MISSING VALUE REPORT =====\n",
      "               Missing_Count  Percent_Missing (%)\n",
      "Price_Billion              0                  0.0\n",
      "Price_Per_m2               0                  0.0\n",
      "Area_m2                    0                  0.0\n",
      "District                   0                  0.0\n",
      "Ward                       0                  0.0\n",
      "Bedrooms                   0                  0.0\n",
      "Is_MatTien                 0                  0.0\n",
      "Width_m                    0                  0.0\n",
      "Floors                     0                  0.0\n",
      "Is Hem                     0                  0.0\n",
      "Post Time                  0                  0.0\n",
      "Toilets                    0                  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               Missing_Count  Percent_Missing (%)\n",
       "Price_Billion              0                  0.0\n",
       "Price_Per_m2               0                  0.0\n",
       "Area_m2                    0                  0.0\n",
       "District                   0                  0.0\n",
       "Ward                       0                  0.0\n",
       "Bedrooms                   0                  0.0\n",
       "Is_MatTien                 0                  0.0\n",
       "Width_m                    0                  0.0\n",
       "Floors                     0                  0.0\n",
       "Is Hem                     0                  0.0\n",
       "Post Time                  0                  0.0\n",
       "Toilets                    0                  0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Percent_Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price_Billion</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Per_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area_m2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ward</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is_MatTien</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width_m</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Floors</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is Hem</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toilets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
